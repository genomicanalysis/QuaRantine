<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Week 4 Machine learning | 40 Days and 40 Nights</title>
  <meta name="description" content="An ad hoc course to learn R for bioinformatics, using the
COVID-19 epidemic as an excuse." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Week 4 Machine learning | 40 Days and 40 Nights" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An ad hoc course to learn R for bioinformatics, using the
COVID-19 epidemic as an excuse." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Week 4 Machine learning | 40 Days and 40 Nights" />
  
  <meta name="twitter:description" content="An ad hoc course to learn R for bioinformatics, using the
COVID-19 epidemic as an excuse." />
  

<meta name="author" content="Martin Morgan" />
<meta name="author" content="L. Shawn Matott" />


<meta name="date" content="2020-05-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="three.html"/>
<link rel="next" href="five.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">QuaRantine</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Motivation</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#introduction"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-to-expect"><i class="fa fa-check"></i>What to expect</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="one.html"><a href="one.html"><i class="fa fa-check"></i><b>1</b> Basics</a><ul>
<li class="chapter" data-level="1.1" data-path="one.html"><a href="one.html#day-1-monday-zoom-orientation"><i class="fa fa-check"></i><b>1.1</b> Day 1 (Monday) Zoom orientation</a><ul>
<li class="chapter" data-level="1.1.1" data-path="one.html"><a href="one.html#logistics-10-minutes"><i class="fa fa-check"></i><b>1.1.1</b> Logistics (10 minutes)</a></li>
<li class="chapter" data-level="1.1.2" data-path="one.html"><a href="one.html#installing-r-and-rstudio-25-minutes-shawn"><i class="fa fa-check"></i><b>1.1.2</b> Installing <em>R</em> and <em>RStudio</em> (25 minutes, Shawn)</a></li>
<li class="chapter" data-level="1.1.3" data-path="one.html"><a href="one.html#basics-of-r-25-minutes"><i class="fa fa-check"></i><b>1.1.3</b> Basics of <em>R</em> (25 minutes)</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="one.html"><a href="one.html#day-2-vectors-and-variables"><i class="fa fa-check"></i><b>1.2</b> Day 2: Vectors and variables</a></li>
<li class="chapter" data-level="1.3" data-path="one.html"><a href="one.html#day-3-factor-date-and-na"><i class="fa fa-check"></i><b>1.3</b> Day 3: <code>factor()</code>, <code>Date()</code>, and <code>NA</code></a></li>
<li class="chapter" data-level="1.4" data-path="one.html"><a href="one.html#day-4-working-with-variables"><i class="fa fa-check"></i><b>1.4</b> Day 4: Working with variables</a></li>
<li class="chapter" data-level="1.5" data-path="one.html"><a href="one.html#day-5-friday-zoom-check-in"><i class="fa fa-check"></i><b>1.5</b> Day 5 (Friday) Zoom check-in</a><ul>
<li class="chapter" data-level="1.5.1" data-path="one.html"><a href="one.html#logistics"><i class="fa fa-check"></i><b>1.5.1</b> Logistics</a></li>
<li class="chapter" data-level="1.5.2" data-path="one.html"><a href="one.html#review-and-trouble-shoot-25-minutes-martin"><i class="fa fa-check"></i><b>1.5.2</b> Review and trouble shoot (25 minutes; Martin)</a></li>
<li class="chapter" data-level="1.5.3" data-path="one.html"><a href="one.html#weekend-activities-25-minutes-shawn"><i class="fa fa-check"></i><b>1.5.3</b> Weekend activities (25 minutes; Shawn)</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="one.html"><a href="one.html#day-6-r-scripts"><i class="fa fa-check"></i><b>1.6</b> Day 6: <em>R</em> scripts</a></li>
<li class="chapter" data-level="1.7" data-path="one.html"><a href="one.html#day-7-saving-data"><i class="fa fa-check"></i><b>1.7</b> Day 7: Saving data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="two.html"><a href="two.html"><i class="fa fa-check"></i><b>2</b> The data frame</a><ul>
<li class="chapter" data-level="2.1" data-path="two.html"><a href="two.html#day-8-monday-zoom-check-in"><i class="fa fa-check"></i><b>2.1</b> Day 8 (Monday) Zoom check-in</a><ul>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#logistics-1"><i class="fa fa-check"></i>Logistics</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#review-and-troubleshoot-15-minutes"><i class="fa fa-check"></i>Review and troubleshoot (15 minutes)</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#the-data-frame-40-minutes"><i class="fa fa-check"></i>The data frame (40 minutes)</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#this-weeks-activities-5-minutes"><i class="fa fa-check"></i>This week’s activities (5 minutes)</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="two.html"><a href="two.html#day-9-creation-and-manipulation"><i class="fa fa-check"></i><b>2.2</b> Day 9: Creation and manipulation</a><ul>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#creation"><i class="fa fa-check"></i>Creation</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#column-selection"><i class="fa fa-check"></i>Column selection</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#adding-or-updating-columns"><i class="fa fa-check"></i>Adding or updating columns</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#reading-and-writing"><i class="fa fa-check"></i>Reading and writing</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#reading-from-a-remote-file"><i class="fa fa-check"></i>Reading from a remote file (!)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="two.html"><a href="two.html#day-10-subset-with-and-within"><i class="fa fa-check"></i><b>2.3</b> Day 10: <code>subset()</code>, <code>with()</code>, and <code>within()</code></a><ul>
<li><a href="two.html#subset"><code>subset()</code></a></li>
<li><a href="two.html#with"><code>with()</code></a></li>
<li><a href="two.html#within"><code>within()</code></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="two.html"><a href="two.html#day-11-aggregate-and-an-initial-work-flow"><i class="fa fa-check"></i><b>2.4</b> Day 11: <code>aggregate()</code> and an initial work flow</a><ul>
<li><a href="two.html#aggregate-for-summarizing-columns-by-group"><code>aggregate()</code> for summarizing columns by group</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#an-initial-work-flow"><i class="fa fa-check"></i>An initial work flow</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="two.html"><a href="two.html#day-12-friday-zoom-check-in"><i class="fa fa-check"></i><b>2.5</b> Day 12 (Friday) Zoom check-in</a><ul>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#review-and-troubleshoot-20-minutes"><i class="fa fa-check"></i>Review and troubleshoot (20 minutes)</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#user-defined-functions"><i class="fa fa-check"></i>User-defined functions</a></li>
<li class="chapter" data-level="" data-path="two.html"><a href="two.html#plotting-data"><i class="fa fa-check"></i>Plotting data</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="two.html"><a href="two.html#day-13-basic-visualization"><i class="fa fa-check"></i><b>2.6</b> Day 13: Basic visualization</a></li>
<li class="chapter" data-level="2.7" data-path="two.html"><a href="two.html#day-14-functions"><i class="fa fa-check"></i><b>2.7</b> Day 14: Functions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="three.html"><a href="three.html"><i class="fa fa-check"></i><b>3</b> Packages and the ‘tidyverse’</a><ul>
<li class="chapter" data-level="3.1" data-path="three.html"><a href="three.html#day-15-monday-zoom-check-in"><i class="fa fa-check"></i><b>3.1</b> Day 15 (Monday) Zoom check-in</a><ul>
<li class="chapter" data-level="" data-path="three.html"><a href="three.html#review-and-troubleshoot-15-minutes-1"><i class="fa fa-check"></i>Review and troubleshoot (15 minutes)</a></li>
<li class="chapter" data-level="" data-path="three.html"><a href="three.html#packages-20-minutes"><i class="fa fa-check"></i>Packages (20 minutes)</a></li>
<li class="chapter" data-level="" data-path="three.html"><a href="three.html#the-tidyverse-of-packages-20-minutes"><i class="fa fa-check"></i>The ‘tidyverse’ of packages (20 minutes)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="three.html"><a href="three.html#day-16-key-tidyverse-packages-readr-and-dplyr"><i class="fa fa-check"></i><b>3.2</b> Day 16 Key tidyverse packages: <span>readr</span> and <span>dplyr</span></a></li>
<li class="chapter" data-level="3.3" data-path="three.html"><a href="three.html#day-17-visualization-with-ggplot2"><i class="fa fa-check"></i><b>3.3</b> Day 17 Visualization with <span>ggplot2</span></a><ul>
<li class="chapter" data-level="" data-path="three.html"><a href="three.html#setup"><i class="fa fa-check"></i>Setup</a></li>
<li><a href="three.html#ggplot2-essentials"><span>ggplot2</span> essentials</a></li>
<li class="chapter" data-level="" data-path="three.html"><a href="three.html#covid-19-in-erie-county"><i class="fa fa-check"></i>COVID-19 in Erie county</a></li>
<li class="chapter" data-level="" data-path="three.html"><a href="three.html#covid-19-in-new-york-state"><i class="fa fa-check"></i>COVID-19 in New York State</a></li>
<li class="chapter" data-level="" data-path="three.html"><a href="three.html#covid-19-nationally"><i class="fa fa-check"></i>COVID-19 nationally</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="three.html"><a href="three.html#day-18-worldwide-covid-data"><i class="fa fa-check"></i><b>3.4</b> Day 18 Worldwide COVID data</a></li>
<li class="chapter" data-level="3.5" data-path="three.html"><a href="three.html#day-19-friday-zoom-check-in"><i class="fa fa-check"></i><b>3.5</b> Day 19 (Friday) Zoom check-in</a><ul>
<li class="chapter" data-level="3.5.1" data-path="three.html"><a href="three.html#logistics-2"><i class="fa fa-check"></i><b>3.5.1</b> Logistics</a></li>
<li class="chapter" data-level="3.5.2" data-path="three.html"><a href="three.html#review-and-trouble-shoot-40-minutes"><i class="fa fa-check"></i><b>3.5.2</b> Review and trouble shoot (40 minutes)</a></li>
<li class="chapter" data-level="3.5.3" data-path="three.html"><a href="three.html#weekend-activities-15-minutes"><i class="fa fa-check"></i><b>3.5.3</b> Weekend activities (15 minutes)</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="three.html"><a href="three.html#day-20-exploring-the-course-of-pandemic-in-different-regions"><i class="fa fa-check"></i><b>3.6</b> Day 20 Exploring the course of pandemic in different regions</a></li>
<li class="chapter" data-level="3.7" data-path="three.html"><a href="three.html#day-21"><i class="fa fa-check"></i><b>3.7</b> Day 21</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="four.html"><a href="four.html"><i class="fa fa-check"></i><b>4</b> Machine learning</a><ul>
<li class="chapter" data-level="4.1" data-path="four.html"><a href="four.html#day-22-monday-zoom-check-in"><i class="fa fa-check"></i><b>4.1</b> Day 22 (Monday) Zoom check-in</a><ul>
<li class="chapter" data-level="4.1.1" data-path="four.html"><a href="four.html#a-machine-learning-primer"><i class="fa fa-check"></i><b>4.1.1</b> A Machine Learning Primer</a></li>
<li class="chapter" data-level="4.1.2" data-path="four.html"><a href="four.html#the-random-forest-algorithm"><i class="fa fa-check"></i><b>4.1.2</b> The Random Forest Algorithm</a></li>
<li class="chapter" data-level="4.1.3" data-path="four.html"><a href="four.html#a-covid-19-dataset-for-machine-learning"><i class="fa fa-check"></i><b>4.1.3</b> A COVID-19 Dataset for Machine Learning</a></li>
<li class="chapter" data-level="4.1.4" data-path="four.html"><a href="four.html#a-random-forest-example-using-covid-19-data"><i class="fa fa-check"></i><b>4.1.4</b> A Random Forest Example Using COVID-19 Data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="four.html"><a href="four.html#day-23---support-vector-machines"><i class="fa fa-check"></i><b>4.2</b> Day 23 - Support Vector Machines</a><ul>
<li class="chapter" data-level="4.2.1" data-path="four.html"><a href="four.html#an-svm-example-using-covid-19"><i class="fa fa-check"></i><b>4.2.1</b> An SVM Example using COVID-19</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="four.html"><a href="four.html#day-24---the-k-nearest-neighbors-algorithm"><i class="fa fa-check"></i><b>4.3</b> Day 24 - the <span class="math inline">\(k\)</span>-Nearest Neighbors Algorithm</a></li>
<li class="chapter" data-level="4.4" data-path="four.html"><a href="four.html#day-25---artificial-neural-networks"><i class="fa fa-check"></i><b>4.4</b> Day 25 - Artificial Neural Networks</a><ul>
<li class="chapter" data-level="4.4.1" data-path="four.html"><a href="four.html#introduction-to-artifical-neural-networks"><i class="fa fa-check"></i><b>4.4.1</b> Introduction to Artifical Neural Networks</a></li>
<li class="chapter" data-level="4.4.2" data-path="four.html"><a href="four.html#keras-and-tensorflow"><i class="fa fa-check"></i><b>4.4.2</b> Keras and TensorFlow</a></li>
<li class="chapter" data-level="4.4.3" data-path="four.html"><a href="four.html#applying-keras-and-tensorflow-to-the-covid-19-dataset"><i class="fa fa-check"></i><b>4.4.3</b> Applying Keras and TensorFlow to the COVID-19 Dataset</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="four.html"><a href="four.html#day-26-friday-zoom-check-in"><i class="fa fa-check"></i><b>4.5</b> Day 26 (Friday) Zoom check-in</a><ul>
<li class="chapter" data-level="4.5.1" data-path="four.html"><a href="four.html#review-and-trouble-shoot-25-minutes"><i class="fa fa-check"></i><b>4.5.1</b> Review and trouble shoot (25 minutes)</a></li>
<li class="chapter" data-level="4.5.2" data-path="four.html"><a href="four.html#this-weekend-25-minutes"><i class="fa fa-check"></i><b>4.5.2</b> This weekend (25 minutes)</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="four.html"><a href="four.html#day-27"><i class="fa fa-check"></i><b>4.6</b> Day 27</a></li>
<li class="chapter" data-level="4.7" data-path="four.html"><a href="four.html#day-28"><i class="fa fa-check"></i><b>4.7</b> Day 28</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="five.html"><a href="five.html"><i class="fa fa-check"></i><b>5</b> Bioinformatics with <span>Bioconductor</span></a><ul>
<li class="chapter" data-level="5.1" data-path="five.html"><a href="five.html#day-29-monday-zoom-check-in"><i class="fa fa-check"></i><b>5.1</b> Day 29 (Monday) Zoom check-in</a></li>
<li class="chapter" data-level="5.2" data-path="five.html"><a href="five.html#day-30"><i class="fa fa-check"></i><b>5.2</b> Day 30</a></li>
<li class="chapter" data-level="5.3" data-path="five.html"><a href="five.html#day-31"><i class="fa fa-check"></i><b>5.3</b> Day 31</a></li>
<li class="chapter" data-level="5.4" data-path="five.html"><a href="five.html#day-32"><i class="fa fa-check"></i><b>5.4</b> Day 32</a></li>
<li class="chapter" data-level="5.5" data-path="five.html"><a href="five.html#day-33-friday-zoom-check-in"><i class="fa fa-check"></i><b>5.5</b> Day 33 (Friday) Zoom check-in</a><ul>
<li class="chapter" data-level="5.5.1" data-path="five.html"><a href="five.html#review-and-trouble-shoot-25-minutes-1"><i class="fa fa-check"></i><b>5.5.1</b> Review and trouble shoot (25 minutes)</a></li>
<li class="chapter" data-level="5.5.2" data-path="five.html"><a href="five.html#next-week-25-minutes"><i class="fa fa-check"></i><b>5.5.2</b> Next week (25 minutes)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="five.html"><a href="five.html#day-34"><i class="fa fa-check"></i><b>5.6</b> Day 34</a></li>
<li class="chapter" data-level="5.7" data-path="five.html"><a href="five.html#day-35"><i class="fa fa-check"></i><b>5.7</b> Day 35</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="six.html"><a href="six.html"><i class="fa fa-check"></i><b>6</b> Collaboration</a><ul>
<li class="chapter" data-level="6.1" data-path="six.html"><a href="six.html#days-monday-zoom-check-in"><i class="fa fa-check"></i><b>6.1</b> 5 Days (Monday) Zoom check-in</a></li>
<li class="chapter" data-level="6.2" data-path="six.html"><a href="six.html#days"><i class="fa fa-check"></i><b>6.2</b> 4 Days</a></li>
<li class="chapter" data-level="6.3" data-path="six.html"><a href="six.html#days-1"><i class="fa fa-check"></i><b>6.3</b> 3 Days</a></li>
<li class="chapter" data-level="6.4" data-path="six.html"><a href="six.html#days-2"><i class="fa fa-check"></i><b>6.4</b> 2 Days</a></li>
<li class="chapter" data-level="6.5" data-path="six.html"><a href="six.html#today-friday-zoom-check-in"><i class="fa fa-check"></i><b>6.5</b> Today! (Friday) Zoom check-in</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="frequently-asked-questions.html"><a href="frequently-asked-questions.html"><i class="fa fa-check"></i>Frequently asked questions</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">40 Days and 40 Nights</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="four" class="section level1">
<h1><span class="header-section-number">Week 4</span> Machine learning</h1>
<p>This week you will learn about machine learning for classification using <em>R</em>. Objectives are:</p>
<ul>
<li><p>To provide an overview of the underlying concepts of machine learning for classification.</p></li>
<li><p>To provide an introduction to some popular classification algorithms.</p></li>
<li><p>To explore these classification algorithms using various packages in <em>R</em>.</p></li>
<li><p>To apply various classification algorithms to the statewide COVID-19 dataset.</p></li>
</ul>
<div id="day-22-monday-zoom-check-in" class="section level2">
<h2><span class="header-section-number">4.1</span> Day 22 (Monday) Zoom check-in</h2>
<p>Here is an overview of what we’ll cover in today’s Zoom session:</p>
<ul>
<li><p>Overview of Machine Learning for Classification (30 minutes)</p></li>
<li><p>Introduction to the Random Forest algorithm (5 minutes)</p></li>
<li><p>A Random Forest Example in <em>R</em> using COVID-19 Data (25 minutes)</p></li>
</ul>
<div id="a-machine-learning-primer" class="section level3">
<h3><span class="header-section-number">4.1.1</span> A Machine Learning Primer</h3>
<p>Machine Learning (ML) may be defined as using computers to make inferences about data.</p>
<ul>
<li>A mapping of inputs to outputs, Y = f(<em>X</em> , <em><span class="math inline">\(\beta\)</span></em>)</li>
</ul>
<p><em>ML for Classification</em> refers to algorithms that map inputs to a discrete set of outputs (i.e. classes or categories)</p>
<ul>
<li><p>For example, predicting health risk (mild, moderate, severe) based on patient data (height [m], weight [kg], age [years], smoker [yes/no], etc.)</p></li>
<li><p>Or predicting <a href="https://en.wikipedia.org/wiki/Pandemic_severity_index">pandemic severity index</a> (PSI) of COVID-19 in a state based on statewide population data.</p></li>
</ul>
<pre><code>##  PSI Death.Rate    Example     
##  1   &lt; 0.1%        seasonal flu
##  2   0.1% - 0.5%   Asian flu   
##  3   0.5% - 1.0%   n/a         
##  4   1.0% - 2.0%   n/a         
##  5   &gt; 2.0%        Spanish flu</code></pre>
<ul>
<li><p>Predictions are typically expressed as a vector of probabilities.</p>
<ul>
<li><p>e.g. Pr(cancerous) vs. Pr(benign)</p></li>
<li><p>e.g. Pr(PSI=1), Pr(PSI=2), …, Pr(PSI=5)</p></li>
</ul></li>
</ul>
<div id="a-black-box-view-of-machine-learning" class="section level4 unnumbered">
<h4>A “Black Box” View of Machine Learning</h4>
<p>The diagram below illustrates the machine learning concept in terms of a “black box” model that converts inputs into predictions.</p>
<p><img src="images/ml_black_box_generic.png" width="50%" style="display: block; margin: auto;" /></p>
</div>
<div id="a-black-box-example" class="section level4 unnumbered">
<h4>A “Black Box” Example</h4>
<p>The diagram below illustrates a more concrete machine learning model that converts height, weight, and age into a prediction of whether or not the individual is male or female.</p>
<p><img src="images/ml_black_box_example.png" width="50%" style="display: block; margin: auto;" /></p>
</div>
<div id="some-important-machine-learning-terms" class="section level4 unnumbered">
<h4>Some Important Machine Learning Terms</h4>
<p>The above example highlights some important machine learning terminology:</p>
<ul>
<li><p><em>Features</em> (<em>X</em>): Features are the inputs to the model. They are also known as descriptive attributes or explanatory variables. In terms of <em>R</em>, a single set of features corresponds to a tuple or row of data and a complete set of feature data maps nicely to a data frame or tibble.</p></li>
<li><p><em>Parameters</em> (<em><span class="math inline">\(\beta\)</span></em>): Parameters are internal variables of the selected machine learning algorithm. They are also known as coefficients or training weights. These internal parameters need to be adjusted to minimize the deviation between predictions and observations. The machine learning algorithms and pacakages that we’ll be using in <em>R</em> take care of this minimization process for us.</p></li>
<li><p><em>Labels</em> (<em>Y</em>): Labels are the outputs of the algorithm, corresponding to the categories you are attempting to predict.</p></li>
<li><p><em>Training Data</em>: Training data is a data set containing paired observations of inputs (i.e features) and outputs (i.e. labels). Training data is also known as measurement data, observation data or calibration data.</p></li>
<li><p><em>Training</em>: Training is the process of adjusting internal algorithm paramters (<em><span class="math inline">\(\beta\)</span></em>) to obtain the best possible match between training data and corresponding model predictions. Training is also known as model calibration or parameter estimation.</p></li>
</ul>
<p>An example set of training data that could be used in the gender prediction example is given below. The frist three columns contain feature data and the last column contains label data. We could use this data to train a model to predict a person’s gender based on their height, weight and age.</p>
<pre><code>##  height_m weight_kg age_y gender
##  1.69      62       30    male  
##  1.74      76       27    female
##  1.92      82       25    male  
##  1.80     100       41    male  
##  1.59      47       24    female
##  1.85      75       26    male  
##  1.75      63       33    female
##  1.96      83       33    male  
##  1.85      39       32    male  
##  1.78      58       28    female
##  1.74      70       30    female
##  1.81      57       26    female
##  1.73      78       32    male</code></pre>
<ul>
<li><em>Test Data</em>: Like training data, test data is a data set containing paired observations of inputs (i.e features) and outputs (i.e. labels). However, test data is deliberately <em>not included</em> in the training process. Performance measures computed using test data help to quantify the expected performance of the model if/when it is applied to unlabeled data.</li>
</ul>
<p>Upon completion of training, it is important to evaluate the quality of the model and its skill or ability at making correct predictions. Some terms related to this evaluation process are defined below:</p>
<ul>
<li><p><em>Classification Accuracy</em>: Classification accuracy is the ratio of correct predictions to the total predictions. Classification accuracy can be computed using the training data set or using the test data set.</p></li>
<li><p><em>Confusion Matrix</em>: The confusion matrix is a more detailed summary (relative to classification accuracy) of the performance of a classification algorithm. The diagonals of the confusion matrix count how often the algorithm yields the correct classification for each class. The off-diagonal entries count how often the algorithm confuses one class with another.</p></li>
</ul>
<p>The figure below illustrates the classification accuracy and confusion matrix for an example that attempts to classify images of fruits.</p>
<p><img src="images/ml_ca_fruits_example.png" width="50%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-machine-learning-process" class="section level4 unnumbered">
<h4>The Machine Learning Process</h4>
<p>Now that we’ve defined some of the important machine learning terminology let’s take a 30,000 foot view at the overall machine learning process. This is a general description of the process that you can follow each time you build and use a machine learning model. The process is illustrated in the figure below (with credit to <a href="https://blog.usejournal.com/machine-learning-for-beginners-from-zero-level-8be5b89bf77c">Jinesh Maloo</a>):</p>
<p><img src="images/ml_process_maloo.png" width="75%" style="display: block; margin: auto;" /></p>
<ul>
<li><p>Step 1: Prepare labeled data for training and validation.</p></li>
<li><p>Step 2: Select a machine learning algorithm (i.e. model).</p></li>
<li><p>Step 3: Train the model.</p></li>
<li><p>Step 4: Evaluate model performance.</p></li>
<li><p>If model is useful:</p>
<ul>
<li>Step 5: Apply to unlabled data.</li>
</ul></li>
<li><p>Else (needs improvement):</p>
<ul>
<li><p>Collect more data (go back to Step 1).</p></li>
<li><p>Revise model (go back to Step 2)</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="the-random-forest-algorithm" class="section level3">
<h3><span class="header-section-number">4.1.2</span> The Random Forest Algorithm</h3>
<p>The random forest algorithm is a popular choice for machine learning.</p>
<ul>
<li><p>Over 20 <em>R</em> packages have an implementation of some form of the algorithm.</p></li>
<li><p>We’ll be using the <code>randomForest</code> pacakge.</p></li>
<li><p>The algorithm is like <code>bagging</code> (boostrap aggregating) regression trees, but the rgression trees are de-correlated.</p></li>
</ul>
<p>The figure below illustrates one possible <code>tree</code> in a <code>random forest</code> for a gender prediction model. In computer science terminology, each split in the figure is a <code>branch</code> of a graph <code>tree</code>. In simple terms, the split points are randomly generated and the resulting <code>trees</code> combine to form a <code>random forest</code>.</p>
<p><img src="images/ml_rf_tree_gender.png" width="50%" style="display: block; margin: auto;" /></p>
<p>The figure below illustrates a set of 6 <code>trees</code> that make up a <code>random forest</code> for predicting housing prices. The image is courtesy <a href="https://uc-r.github.io/random_forests">Bradley Boehmke at the University of Cincinnati</a>. Examine the figure closely and notice that:</p>
<ul>
<li><p>The split variables can differ across trees (not all variables are included in all trees).</p></li>
<li><p>The split variables can differ within trees (not all paths consider the same set of variables).</p></li>
<li><p>The order of splits can differ.</p></li>
<li><p>The split values can differ.</p></li>
</ul>
<p><img src="images/ml_rf_tree_housing.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The job of the random forest algorithm is to determine the optimal set of trees for your data set, including the splitting configuration of each tree (i.e. order, values, etc.).</p>
<p>Now you have a basic understanding of machine learning and the random forest algorithm. You’re probably excited to get going with applying the algorithm! But first, we need to have a data set to work with. In the next section you’ll learn about a data set that can be used for predicting the severity of COVID-19 in a state.</p>
</div>
<div id="a-covid-19-dataset-for-machine-learning" class="section level3">
<h3><span class="header-section-number">4.1.3</span> A COVID-19 Dataset for Machine Learning</h3>
<p>We’d like to predict the severity of COVID-19 in a given state using statewide <em>feature</em> data like population, urban density, number of hospital beds, date of stay at home order, etc. We’ve already seen that we can get the information about cases and deaths from the New York Times github page. However, gathering corresponding statewide feature data requires quite a bit of hunting through various public websites. Consequently, we’re going to skip over the painstaking process of marshalling the feature data and just provide you with a dataset that is already nice and prepped for machine learning.</p>
<p>You’ll work with two <code>.csv</code> files - a <em>data</em> file that contains a veriety of statewide data, and a <em>metadata</em> file that describes the various columns of the data file. This combination of data and metadata files is a common way of sharing datasets.</p>
<p>To give you an idea of what was involved in assembling the data and metadata file, a summary of the data collection and processing steps is given below:</p>
<ul>
<li><p>First, a snapshot of the New York Times (NYT) COVID-19 data from April 27th was downloaded from the <a href="https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv">nytimes github repo</a> and stored on local disk.</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb299-1" data-line-number="1">url &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&quot;</span></a>
<a class="sourceLine" id="cb299-2" data-line-number="2">file &lt;-<span class="st"> &quot;us-counties_04_27_2020.csv&quot;</span></a>
<a class="sourceLine" id="cb299-3" data-line-number="3">destination &lt;-<span class="st"> </span><span class="kw">file.path</span>(<span class="st">&quot;workdir&quot;</span>, file)</a>
<a class="sourceLine" id="cb299-4" data-line-number="4"><span class="kw">download.file</span>(url, destination)</a></code></pre></div></li>
<li><p>The NYT COVID-19 data was processed using <em>R</em> :</p>
<ul>
<li><p>The cases and deaths in <code>us-counties_04_27_2020.csv</code> were aggregated into statewide values.</p></li>
<li><p>The death rate was calculated and categorized according to an 8-point severity index.</p></li>
<li><p>Finally, the statewide data (augmented with death rate and severity index) was exported as a <code>.csv</code> file.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb300-1" data-line-number="1"><span class="kw">library</span>(readr)</a>
<a class="sourceLine" id="cb300-2" data-line-number="2"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb300-3" data-line-number="3"><span class="co">## </span></a>
<a class="sourceLine" id="cb300-4" data-line-number="4"><span class="co">## Attaching package: &#39;dplyr&#39;</span></a>
<a class="sourceLine" id="cb300-5" data-line-number="5"><span class="co">## The following objects are masked from &#39;package:stats&#39;:</span></a>
<a class="sourceLine" id="cb300-6" data-line-number="6"><span class="co">## </span></a>
<a class="sourceLine" id="cb300-7" data-line-number="7"><span class="co">##     filter, lag</span></a>
<a class="sourceLine" id="cb300-8" data-line-number="8"><span class="co">## The following objects are masked from &#39;package:base&#39;:</span></a>
<a class="sourceLine" id="cb300-9" data-line-number="9"><span class="co">## </span></a>
<a class="sourceLine" id="cb300-10" data-line-number="10"><span class="co">##     intersect, setdiff, setequal, union</span></a>
<a class="sourceLine" id="cb300-11" data-line-number="11"></a>
<a class="sourceLine" id="cb300-12" data-line-number="12"><span class="co">## get data from file</span></a>
<a class="sourceLine" id="cb300-13" data-line-number="13">covid_data_file &lt;-<span class="st"> </span><span class="kw">file.path</span>(<span class="st">&quot;./workdir&quot;</span>, <span class="st">&quot;us-counties_04_27_2020.csv&quot;</span>)</a>
<a class="sourceLine" id="cb300-14" data-line-number="14"></a>
<a class="sourceLine" id="cb300-15" data-line-number="15"><span class="co">## read the data as a tibble</span></a>
<a class="sourceLine" id="cb300-16" data-line-number="16">us_data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(covid_data_file)</a>
<a class="sourceLine" id="cb300-17" data-line-number="17"><span class="co">## Parsed with column specification:</span></a>
<a class="sourceLine" id="cb300-18" data-line-number="18"><span class="co">## cols(</span></a>
<a class="sourceLine" id="cb300-19" data-line-number="19"><span class="co">##   date = col_date(format = &quot;&quot;),</span></a>
<a class="sourceLine" id="cb300-20" data-line-number="20"><span class="co">##   county = col_character(),</span></a>
<a class="sourceLine" id="cb300-21" data-line-number="21"><span class="co">##   state = col_character(),</span></a>
<a class="sourceLine" id="cb300-22" data-line-number="22"><span class="co">##   fips = col_character(),</span></a>
<a class="sourceLine" id="cb300-23" data-line-number="23"><span class="co">##   cases = col_double(),</span></a>
<a class="sourceLine" id="cb300-24" data-line-number="24"><span class="co">##   deaths = col_double()</span></a>
<a class="sourceLine" id="cb300-25" data-line-number="25"><span class="co">## )</span></a>
<a class="sourceLine" id="cb300-26" data-line-number="26"></a>
<a class="sourceLine" id="cb300-27" data-line-number="27"><span class="co">## aggregate by county and state</span></a>
<a class="sourceLine" id="cb300-28" data-line-number="28">county_state &lt;-</a>
<a class="sourceLine" id="cb300-29" data-line-number="29"><span class="st">    </span>us_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb300-30" data-line-number="30"><span class="st">    </span><span class="kw">group_by</span>(county, state) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb300-31" data-line-number="31"><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">cases =</span> <span class="kw">max</span>(cases), <span class="dt">deaths =</span> <span class="kw">max</span>(deaths))</a>
<a class="sourceLine" id="cb300-32" data-line-number="32"></a>
<a class="sourceLine" id="cb300-33" data-line-number="33"><span class="co">## aggregate by state</span></a>
<a class="sourceLine" id="cb300-34" data-line-number="34">state &lt;-</a>
<a class="sourceLine" id="cb300-35" data-line-number="35"><span class="st">    </span>county_state <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb300-36" data-line-number="36"><span class="st">    </span><span class="kw">group_by</span>(state) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb300-37" data-line-number="37"><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">cases =</span> <span class="kw">sum</span>(cases), <span class="dt">deaths =</span> <span class="kw">sum</span>(deaths))</a>
<a class="sourceLine" id="cb300-38" data-line-number="38"></a>
<a class="sourceLine" id="cb300-39" data-line-number="39"><span class="co">## calculate death rate</span></a>
<a class="sourceLine" id="cb300-40" data-line-number="40">state &lt;-</a>
<a class="sourceLine" id="cb300-41" data-line-number="41"><span class="st">    </span>state <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb300-42" data-line-number="42"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">death_rate =</span> <span class="fl">100.00</span> <span class="op">*</span><span class="st"> </span>deaths <span class="op">/</span><span class="st"> </span>cases)</a>
<a class="sourceLine" id="cb300-43" data-line-number="43"></a>
<a class="sourceLine" id="cb300-44" data-line-number="44"><span class="co"># Assign the following severity index using cut:</span></a>
<a class="sourceLine" id="cb300-45" data-line-number="45"><span class="co">##  PSI Death.Rate    </span></a>
<a class="sourceLine" id="cb300-46" data-line-number="46"><span class="co">##  1   &lt; 0.1%        </span></a>
<a class="sourceLine" id="cb300-47" data-line-number="47"><span class="co">##  2   0.1% - 0.5%   </span></a>
<a class="sourceLine" id="cb300-48" data-line-number="48"><span class="co">##  3   0.5% - 1.0%   </span></a>
<a class="sourceLine" id="cb300-49" data-line-number="49"><span class="co">##  4   1.0% - 2.0%   </span></a>
<a class="sourceLine" id="cb300-50" data-line-number="50"><span class="co">##  5   2.0% - 4.0%   </span></a>
<a class="sourceLine" id="cb300-51" data-line-number="51"><span class="co">##  6   4.0% - 6.0%   </span></a>
<a class="sourceLine" id="cb300-52" data-line-number="52"><span class="co">##  7   6.0% - 8.0%   </span></a>
<a class="sourceLine" id="cb300-53" data-line-number="53"><span class="co">##  8   &gt;8.0%         </span></a>
<a class="sourceLine" id="cb300-54" data-line-number="54">state &lt;-</a>
<a class="sourceLine" id="cb300-55" data-line-number="55"><span class="st">    </span>state <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb300-56" data-line-number="56"><span class="st">    </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb300-57" data-line-number="57">        <span class="dt">severity_index =</span><span class="kw">cut</span>(</a>
<a class="sourceLine" id="cb300-58" data-line-number="58">            death_rate, </a>
<a class="sourceLine" id="cb300-59" data-line-number="59">            <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="fl">0.0</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">4.0</span>, <span class="fl">6.0</span>, <span class="fl">8.0</span>, <span class="fl">100.0</span>),</a>
<a class="sourceLine" id="cb300-60" data-line-number="60">            <span class="dt">labels =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">8</span></a>
<a class="sourceLine" id="cb300-61" data-line-number="61">        )</a>
<a class="sourceLine" id="cb300-62" data-line-number="62">    )</a>
<a class="sourceLine" id="cb300-63" data-line-number="63"></a>
<a class="sourceLine" id="cb300-64" data-line-number="64"><span class="co">## write out as csv</span></a>
<a class="sourceLine" id="cb300-65" data-line-number="65">my_out_file &lt;-<span class="st"> </span><span class="kw">file.path</span>(<span class="st">&quot;./workdir&quot;</span>, <span class="st">&quot;covid_data.csv&quot;</span>)</a>
<a class="sourceLine" id="cb300-66" data-line-number="66"><span class="kw">write_csv</span>(state, my_out_file)</a></code></pre></div></li>
</ul></li>
<li><p>The resulting statewide COVID-19 <em>label</em> data (i.e. what we would like to predict) was augmented with 32 statewide <em>features</em>, including population, percent urban, number of hospital beds, etc. Feature data was collected from a veriety of sources, including the Center for Disease Control, the American Heart Association, the U.S. Census Bureau, etc. In some cases the feature data was available for direct download (e.g. as a <code>.csv</code> file) and in other cases the feature data was manually harvested (e.g. cut-and-paste from websites).</p></li>
<li><p>The augmented (i.e. features + labels) <code>.csv</code> file was split into two <code>.csv</code> files that you will need to download:</p>
<ul>
<li><p><a href="assets/statewide_covid_19_data_04_27_2020.csv">statewide_covid_19_data_04_27_2020.csv</a>: This file contains the final COVID-19 machine learning data set, but features and labels are coded so that feature columns are named <code>X01</code>, <code>X02</code>, <code>X03</code>, etc. and label colunms are named <code>Y01</code>, <code>Y02</code>, <code>Y03</code>, etc.</p></li>
<li><p><a href="assets/statewide_covid_19_metadata_04_27_2020.csv">statewide_covid_19_metadata_04_27_2020.csv</a>: This file maps the column names in the data file to more meaningful names and desciptions (including units) of the associated variables. For example <code>X01</code> is <code>Pct_Sun</code> and has a description of <code>Percent sunny days</code>. This is known as <em>metadata</em> - data that describes other data.</p></li>
</ul></li>
</ul>
<p>Click on the links above to download the data and metadata files that you’ll need for the machine learning examples presented throughout the week.</p>
</div>
<div id="a-random-forest-example-using-covid-19-data" class="section level3">
<h3><span class="header-section-number">4.1.4</span> A Random Forest Example Using COVID-19 Data</h3>
<p>Let’s apply the random forest algorithm to the COVID-19 dataset. We’ll build out the required <em>R</em> code in sections. To get started, open a new <em>R</em> script in <em>RStudio</em> and name it <code>covid_19_rf.R</code>. Enter the code below, but omit lines that begin with a double-hash (<code>##</code>) because these are the expected output:</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb301-1" data-line-number="1"><span class="co">#</span></a>
<a class="sourceLine" id="cb301-2" data-line-number="2"><span class="co"># Part 1 - load the data</span></a>
<a class="sourceLine" id="cb301-3" data-line-number="3"><span class="co">#</span></a>
<a class="sourceLine" id="cb301-4" data-line-number="4"><span class="kw">library</span>(randomForest)</a>
<a class="sourceLine" id="cb301-5" data-line-number="5"><span class="co">## randomForest 4.6-14</span></a>
<a class="sourceLine" id="cb301-6" data-line-number="6"><span class="co">## Type rfNews() to see new features/changes/bug fixes.</span></a>
<a class="sourceLine" id="cb301-7" data-line-number="7"><span class="co">## </span></a>
<a class="sourceLine" id="cb301-8" data-line-number="8"><span class="co">## Attaching package: &#39;randomForest&#39;</span></a>
<a class="sourceLine" id="cb301-9" data-line-number="9"><span class="co">## The following object is masked from &#39;package:dplyr&#39;:</span></a>
<a class="sourceLine" id="cb301-10" data-line-number="10"><span class="co">## </span></a>
<a class="sourceLine" id="cb301-11" data-line-number="11"><span class="co">##     combine</span></a>
<a class="sourceLine" id="cb301-12" data-line-number="12"><span class="kw">library</span>(readr)</a>
<a class="sourceLine" id="cb301-13" data-line-number="13"></a>
<a class="sourceLine" id="cb301-14" data-line-number="14">data_file &lt;-<span class="st"> </span><span class="kw">file.path</span>(<span class="st">&quot;assets&quot;</span>, <span class="st">&quot;statewide_covid_19_data_04_27_2020.csv&quot;</span>)</a>
<a class="sourceLine" id="cb301-15" data-line-number="15">df &lt;-<span class="st"> </span><span class="kw">read_csv</span>(data_file)</a>
<a class="sourceLine" id="cb301-16" data-line-number="16"><span class="co">## Parsed with column specification:</span></a>
<a class="sourceLine" id="cb301-17" data-line-number="17"><span class="co">## cols(</span></a>
<a class="sourceLine" id="cb301-18" data-line-number="18"><span class="co">##   .default = col_double(),</span></a>
<a class="sourceLine" id="cb301-19" data-line-number="19"><span class="co">##   State = col_character(),</span></a>
<a class="sourceLine" id="cb301-20" data-line-number="20"><span class="co">##   X31 = col_character(),</span></a>
<a class="sourceLine" id="cb301-21" data-line-number="21"><span class="co">##   X32 = col_character()</span></a>
<a class="sourceLine" id="cb301-22" data-line-number="22"><span class="co">## )</span></a>
<a class="sourceLine" id="cb301-23" data-line-number="23"><span class="co">## See spec(...) for full column specifications.</span></a>
<a class="sourceLine" id="cb301-24" data-line-number="24"><span class="co"># coerce severity to a factor (so RF algorithm uses classification)</span></a>
<a class="sourceLine" id="cb301-25" data-line-number="25">df &lt;-</a>
<a class="sourceLine" id="cb301-26" data-line-number="26"><span class="st">    </span>df <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb301-27" data-line-number="27"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Y04 =</span> <span class="kw">as.factor</span>(df<span class="op">$</span>Y04))</a>
<a class="sourceLine" id="cb301-28" data-line-number="28"></a>
<a class="sourceLine" id="cb301-29" data-line-number="29"></a>
<a class="sourceLine" id="cb301-30" data-line-number="30">metadata_file &lt;-<span class="st"> </span><span class="kw">file.path</span>(<span class="st">&quot;assets&quot;</span>, <span class="st">&quot;statewide_covid_19_metadata_04_27_2020.csv&quot;</span>)</a>
<a class="sourceLine" id="cb301-31" data-line-number="31">mdf &lt;-<span class="st"> </span><span class="kw">read_csv</span>(metadata_file)</a>
<a class="sourceLine" id="cb301-32" data-line-number="32"><span class="co">## Parsed with column specification:</span></a>
<a class="sourceLine" id="cb301-33" data-line-number="33"><span class="co">## cols(</span></a>
<a class="sourceLine" id="cb301-34" data-line-number="34"><span class="co">##   ID = col_double(),</span></a>
<a class="sourceLine" id="cb301-35" data-line-number="35"><span class="co">##   Code = col_character(),</span></a>
<a class="sourceLine" id="cb301-36" data-line-number="36"><span class="co">##   Variable = col_character(),</span></a>
<a class="sourceLine" id="cb301-37" data-line-number="37"><span class="co">##   Description = col_character()</span></a>
<a class="sourceLine" id="cb301-38" data-line-number="38"><span class="co">## )</span></a>
<a class="sourceLine" id="cb301-39" data-line-number="39">mdf</a>
<a class="sourceLine" id="cb301-40" data-line-number="40"><span class="co">## # A tibble: 36 x 4</span></a>
<a class="sourceLine" id="cb301-41" data-line-number="41"><span class="co">##       ID Code  Variable             Description                      </span></a>
<a class="sourceLine" id="cb301-42" data-line-number="42"><span class="co">##    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                &lt;chr&gt;                            </span></a>
<a class="sourceLine" id="cb301-43" data-line-number="43"><span class="co">##  1     1 X01   Pct_Sun              Percent sunny days               </span></a>
<a class="sourceLine" id="cb301-44" data-line-number="44"><span class="co">##  2     2 X02   Total_Hours_Sun      Total hours of sun               </span></a>
<a class="sourceLine" id="cb301-45" data-line-number="45"><span class="co">##  3     3 X03   Num_Clear_Days       Number of clear days             </span></a>
<a class="sourceLine" id="cb301-46" data-line-number="46"><span class="co">##  4     4 X04   Avg_RH               Average relative himidity        </span></a>
<a class="sourceLine" id="cb301-47" data-line-number="47"><span class="co">##  5     5 X05   Avg_Dew_Point        Average dew point                </span></a>
<a class="sourceLine" id="cb301-48" data-line-number="48"><span class="co">##  6     6 X06   Total_Population     Total population                 </span></a>
<a class="sourceLine" id="cb301-49" data-line-number="49"><span class="co">##  7     7 X07   Senior_Pop_Thousands Population 65+ years in thousands</span></a>
<a class="sourceLine" id="cb301-50" data-line-number="50"><span class="co">##  8     8 X08   Senior_Pop_Pct       Percentage of population 65+ year</span></a>
<a class="sourceLine" id="cb301-51" data-line-number="51"><span class="co">##  9     9 X09   per_capita_income    per capita income                </span></a>
<a class="sourceLine" id="cb301-52" data-line-number="52"><span class="co">## 10    10 X10   Unemployment_Rate    Percent unemployment             </span></a>
<a class="sourceLine" id="cb301-53" data-line-number="53"><span class="co">## # … with 26 more rows</span></a></code></pre></div>
<p>Try to run the code. You may get an error about missing the <code>randomForest</code> package. You can install it from the RStudio console (see below) or using the installer in the RStudio <code>packages</code> pane.</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb302-1" data-line-number="1"><span class="kw">install.packages</span>(<span class="st">&quot;randomForest&quot;</span>)</a></code></pre></div>
<p>Now we’ve loaded the data and metadata file. Let’s pick a subset of 5 of the features and use them to try and predict the pandemic severity index (i.e. <code>Y04</code>). Add the <code>Part 2</code> code below to your RScript but omit lines that begin with a double-hash (<code>##</code>) :</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb303-1" data-line-number="1"><span class="co">#</span></a>
<a class="sourceLine" id="cb303-2" data-line-number="2"><span class="co"># Part 2 - select features and label</span></a>
<a class="sourceLine" id="cb303-3" data-line-number="3"><span class="co">#</span></a>
<a class="sourceLine" id="cb303-4" data-line-number="4"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb303-5" data-line-number="5"></a>
<a class="sourceLine" id="cb303-6" data-line-number="6"><span class="co"># describe all possible features and labels</span></a>
<a class="sourceLine" id="cb303-7" data-line-number="7"><span class="kw">print</span>(mdf, <span class="dt">n =</span> <span class="kw">nrow</span>(mdf))</a>
<a class="sourceLine" id="cb303-8" data-line-number="8"><span class="co">## # A tibble: 36 x 4</span></a>
<a class="sourceLine" id="cb303-9" data-line-number="9"><span class="co">##       ID Code  Variable           Description                                   </span></a>
<a class="sourceLine" id="cb303-10" data-line-number="10"><span class="co">##    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;              &lt;chr&gt;                                         </span></a>
<a class="sourceLine" id="cb303-11" data-line-number="11"><span class="co">##  1     1 X01   Pct_Sun            Percent sunny days                            </span></a>
<a class="sourceLine" id="cb303-12" data-line-number="12"><span class="co">##  2     2 X02   Total_Hours_Sun    Total hours of sun                            </span></a>
<a class="sourceLine" id="cb303-13" data-line-number="13"><span class="co">##  3     3 X03   Num_Clear_Days     Number of clear days                          </span></a>
<a class="sourceLine" id="cb303-14" data-line-number="14"><span class="co">##  4     4 X04   Avg_RH             Average relative himidity                     </span></a>
<a class="sourceLine" id="cb303-15" data-line-number="15"><span class="co">##  5     5 X05   Avg_Dew_Point      Average dew point                             </span></a>
<a class="sourceLine" id="cb303-16" data-line-number="16"><span class="co">##  6     6 X06   Total_Population   Total population                              </span></a>
<a class="sourceLine" id="cb303-17" data-line-number="17"><span class="co">##  7     7 X07   Senior_Pop_Thousa… Population 65+ years in thousands             </span></a>
<a class="sourceLine" id="cb303-18" data-line-number="18"><span class="co">##  8     8 X08   Senior_Pop_Pct     Percentage of population 65+ year             </span></a>
<a class="sourceLine" id="cb303-19" data-line-number="19"><span class="co">##  9     9 X09   per_capita_income  per capita income                             </span></a>
<a class="sourceLine" id="cb303-20" data-line-number="20"><span class="co">## 10    10 X10   Unemployment_Rate  Percent unemployment                          </span></a>
<a class="sourceLine" id="cb303-21" data-line-number="21"><span class="co">## 11    11 X11   Uninsured_Rate_Ch… Percent uninsured children                    </span></a>
<a class="sourceLine" id="cb303-22" data-line-number="22"><span class="co">## 12    12 X12   Uninsured_Rate_Ad… Percent uninsured adults                      </span></a>
<a class="sourceLine" id="cb303-23" data-line-number="23"><span class="co">## 13    13 X13   Heart_Disease_Rate Deaths per 100000  due to heart disease       </span></a>
<a class="sourceLine" id="cb303-24" data-line-number="24"><span class="co">## 14    14 X14   Heart_Disease_Dea… Total deaths due to heart disease             </span></a>
<a class="sourceLine" id="cb303-25" data-line-number="25"><span class="co">## 15    15 X15   Tobacco_Use_Rate   Percentage of tobacco users                   </span></a>
<a class="sourceLine" id="cb303-26" data-line-number="26"><span class="co">## 16    16 X16   Obesity_Prevalenc… Percentage of population this is considered o…</span></a>
<a class="sourceLine" id="cb303-27" data-line-number="27"><span class="co">## 17    17 X17   Num_Hospitals      Number of hospitals                           </span></a>
<a class="sourceLine" id="cb303-28" data-line-number="28"><span class="co">## 18    18 X18   Num_Hosp_Staffed_… Number of hospital beds                       </span></a>
<a class="sourceLine" id="cb303-29" data-line-number="29"><span class="co">## 19    19 X19   Total_Hosp_Discha… Total number of hospital discharges           </span></a>
<a class="sourceLine" id="cb303-30" data-line-number="30"><span class="co">## 20    20 X20   Hosp_Patient_Days  Total number of patient days in hospital      </span></a>
<a class="sourceLine" id="cb303-31" data-line-number="31"><span class="co">## 21    21 X21   Hosp_Gross_Patien… Total hospital gross patient revenue          </span></a>
<a class="sourceLine" id="cb303-32" data-line-number="32"><span class="co">## 22    22 X22   Number_of_Farms    Total number of farms                         </span></a>
<a class="sourceLine" id="cb303-33" data-line-number="33"><span class="co">## 23    23 X23   Urban_Population_… Percentage of population living in urban areas</span></a>
<a class="sourceLine" id="cb303-34" data-line-number="34"><span class="co">## 24    24 X24   Urban_Population   Total urban population                        </span></a>
<a class="sourceLine" id="cb303-35" data-line-number="35"><span class="co">## 25    25 X25   Urban_Land_Area_S… Amount of urban land area in square miles     </span></a>
<a class="sourceLine" id="cb303-36" data-line-number="36"><span class="co">## 26    26 X26   Urban_Density_Sq_… Urban density in persons per square mile      </span></a>
<a class="sourceLine" id="cb303-37" data-line-number="37"><span class="co">## 27    27 X27   Urban_Land_Pct     Percentage of land use classified as urban    </span></a>
<a class="sourceLine" id="cb303-38" data-line-number="38"><span class="co">## 28    28 X28   Pct_Republican     Percentage of population registered republican</span></a>
<a class="sourceLine" id="cb303-39" data-line-number="39"><span class="co">## 29    29 X29   Pct_Independent    Percentage of population not affiliated with …</span></a>
<a class="sourceLine" id="cb303-40" data-line-number="40"><span class="co">## 30    30 X30   Pct_Democrat       Percentage of population registered democrat  </span></a>
<a class="sourceLine" id="cb303-41" data-line-number="41"><span class="co">## 31    31 X31   Stay_at_Home_Star… Date stay at home order issued                </span></a>
<a class="sourceLine" id="cb303-42" data-line-number="42"><span class="co">## 32    32 X32   Stay_at_Home_End_… Date stay at home order scheduled to be lifted</span></a>
<a class="sourceLine" id="cb303-43" data-line-number="43"><span class="co">## 33     1 Y01   cases              total number of covid-19 cases                </span></a>
<a class="sourceLine" id="cb303-44" data-line-number="44"><span class="co">## 34     2 Y02   deaths             total number of covid-19 deaths               </span></a>
<a class="sourceLine" id="cb303-45" data-line-number="45"><span class="co">## 35     3 Y03   death_rate         death rate as a percentage                    </span></a>
<a class="sourceLine" id="cb303-46" data-line-number="46"><span class="co">## 36     4 Y04   severity_index     severity index based on death_rate: ## 1 = &lt; …</span></a>
<a class="sourceLine" id="cb303-47" data-line-number="47"></a>
<a class="sourceLine" id="cb303-48" data-line-number="48"><span class="co"># select some features and the severity index label</span></a>
<a class="sourceLine" id="cb303-49" data-line-number="49">my_x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;X01&quot;</span>,<span class="st">&quot;X10&quot;</span>,<span class="st">&quot;X12&quot;</span>,<span class="st">&quot;X13&quot;</span>,<span class="st">&quot;X23&quot;</span>)</a>
<a class="sourceLine" id="cb303-50" data-line-number="50">my_y &lt;-<span class="st"> &quot;Y04&quot;</span></a>
<a class="sourceLine" id="cb303-51" data-line-number="51">my_xy &lt;-<span class="st"> </span><span class="kw">c</span>(my_x, my_y)</a>
<a class="sourceLine" id="cb303-52" data-line-number="52"></a>
<a class="sourceLine" id="cb303-53" data-line-number="53"><span class="co"># get descriptions of the selected features and label</span></a>
<a class="sourceLine" id="cb303-54" data-line-number="54">mdf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Code <span class="op">%in%</span><span class="st"> </span>my_xy)</a>
<a class="sourceLine" id="cb303-55" data-line-number="55"><span class="co">## # A tibble: 6 x 4</span></a>
<a class="sourceLine" id="cb303-56" data-line-number="56"><span class="co">##      ID Code  Variable         Description                                      </span></a>
<a class="sourceLine" id="cb303-57" data-line-number="57"><span class="co">##   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt;                                            </span></a>
<a class="sourceLine" id="cb303-58" data-line-number="58"><span class="co">## 1     1 X01   Pct_Sun          Percent sunny days                               </span></a>
<a class="sourceLine" id="cb303-59" data-line-number="59"><span class="co">## 2    10 X10   Unemployment_Ra… Percent unemployment                             </span></a>
<a class="sourceLine" id="cb303-60" data-line-number="60"><span class="co">## 3    12 X12   Uninsured_Rate_… Percent uninsured adults                         </span></a>
<a class="sourceLine" id="cb303-61" data-line-number="61"><span class="co">## 4    13 X13   Heart_Disease_R… Deaths per 100000  due to heart disease          </span></a>
<a class="sourceLine" id="cb303-62" data-line-number="62"><span class="co">## 5    23 X23   Urban_Populatio… Percentage of population living in urban areas   </span></a>
<a class="sourceLine" id="cb303-63" data-line-number="63"><span class="co">## 6     4 Y04   severity_index   severity index based on death_rate: ## 1 = &lt; 0.1…</span></a>
<a class="sourceLine" id="cb303-64" data-line-number="64"></a>
<a class="sourceLine" id="cb303-65" data-line-number="65"><span class="co"># subset the dataframe</span></a>
<a class="sourceLine" id="cb303-66" data-line-number="66">rf_df &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="kw">all_of</span>(my_xy))</a></code></pre></div>
<p>Now we’ll add code to create and train a basic Random Forest model. Add the <code>Part 3</code> code below to your RScript but omit lines that begin with a double-hash (<code>##</code>):</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb304-1" data-line-number="1"><span class="co">#</span></a>
<a class="sourceLine" id="cb304-2" data-line-number="2"><span class="co"># Part 3 - create and train the model</span></a>
<a class="sourceLine" id="cb304-3" data-line-number="3"><span class="co">#</span></a>
<a class="sourceLine" id="cb304-4" data-line-number="4"><span class="co"># split into train (75%) and test (25%) datasets</span></a>
<a class="sourceLine" id="cb304-5" data-line-number="5"><span class="co">#</span></a>
<a class="sourceLine" id="cb304-6" data-line-number="6"><span class="co"># note that `row_nubmer()` generates a vector of row numbers, and</span></a>
<a class="sourceLine" id="cb304-7" data-line-number="7"><span class="co">#     &gt; c(1, 2, 3, 4, 5, 6) %% 4 is</span></a>
<a class="sourceLine" id="cb304-8" data-line-number="8"><span class="co">#     [1] 1 2 3 0 1 2</span></a>
<a class="sourceLine" id="cb304-9" data-line-number="9"></a>
<a class="sourceLine" id="cb304-10" data-line-number="10">train &lt;-<span class="st"> </span>rf_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>((<span class="kw">row_number</span>() <span class="op">%%</span><span class="st"> </span><span class="dv">4</span>) <span class="op">%in%</span><span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb304-11" data-line-number="11">test &lt;-<span class="st"> </span>rf_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">row_number</span>() <span class="op">%%</span><span class="st"> </span><span class="dv">4</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb304-12" data-line-number="12"></a>
<a class="sourceLine" id="cb304-13" data-line-number="13"><span class="co"># create and train the RF model</span></a>
<a class="sourceLine" id="cb304-14" data-line-number="14">model &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Y04 <span class="op">~</span><span class="st"> </span>X01 <span class="op">+</span><span class="st"> </span>X10 <span class="op">+</span><span class="st"> </span>X12 <span class="op">+</span><span class="st"> </span>X13 <span class="op">+</span><span class="st"> </span>X23, </a>
<a class="sourceLine" id="cb304-15" data-line-number="15">                      <span class="dt">data =</span> train)</a>
<a class="sourceLine" id="cb304-16" data-line-number="16"></a>
<a class="sourceLine" id="cb304-17" data-line-number="17"><span class="co"># show results, includes confusion matrix for training data</span></a>
<a class="sourceLine" id="cb304-18" data-line-number="18">model</a>
<a class="sourceLine" id="cb304-19" data-line-number="19"><span class="co">## </span></a>
<a class="sourceLine" id="cb304-20" data-line-number="20"><span class="co">## Call:</span></a>
<a class="sourceLine" id="cb304-21" data-line-number="21"><span class="co">##  randomForest(formula = Y04 ~ X01 + X10 + X12 + X13 + X23, data = train) </span></a>
<a class="sourceLine" id="cb304-22" data-line-number="22"><span class="co">##                Type of random forest: classification</span></a>
<a class="sourceLine" id="cb304-23" data-line-number="23"><span class="co">##                      Number of trees: 500</span></a>
<a class="sourceLine" id="cb304-24" data-line-number="24"><span class="co">## No. of variables tried at each split: 2</span></a>
<a class="sourceLine" id="cb304-25" data-line-number="25"><span class="co">## </span></a>
<a class="sourceLine" id="cb304-26" data-line-number="26"><span class="co">##         OOB estimate of  error rate: 63.16%</span></a>
<a class="sourceLine" id="cb304-27" data-line-number="27"><span class="co">## Confusion matrix:</span></a>
<a class="sourceLine" id="cb304-28" data-line-number="28"><span class="co">##   3 4 5 6 7 8 class.error</span></a>
<a class="sourceLine" id="cb304-29" data-line-number="29"><span class="co">## 3 0 0 1 0 0 0   1.0000000</span></a>
<a class="sourceLine" id="cb304-30" data-line-number="30"><span class="co">## 4 0 0 1 1 0 0   1.0000000</span></a>
<a class="sourceLine" id="cb304-31" data-line-number="31"><span class="co">## 5 0 0 8 7 0 0   0.4666667</span></a>
<a class="sourceLine" id="cb304-32" data-line-number="32"><span class="co">## 6 0 1 8 6 0 0   0.6000000</span></a>
<a class="sourceLine" id="cb304-33" data-line-number="33"><span class="co">## 7 0 0 1 3 0 0   1.0000000</span></a>
<a class="sourceLine" id="cb304-34" data-line-number="34"><span class="co">## 8 0 0 0 1 0 0   1.0000000</span></a>
<a class="sourceLine" id="cb304-35" data-line-number="35"></a>
<a class="sourceLine" id="cb304-36" data-line-number="36"><span class="co"># measure of parameter importance</span></a>
<a class="sourceLine" id="cb304-37" data-line-number="37"><span class="kw">importance</span>(model) </a>
<a class="sourceLine" id="cb304-38" data-line-number="38"><span class="co">##     MeanDecreaseGini</span></a>
<a class="sourceLine" id="cb304-39" data-line-number="39"><span class="co">## X01         3.846554</span></a>
<a class="sourceLine" id="cb304-40" data-line-number="40"><span class="co">## X10         5.553336</span></a>
<a class="sourceLine" id="cb304-41" data-line-number="41"><span class="co">## X12         5.896515</span></a>
<a class="sourceLine" id="cb304-42" data-line-number="42"><span class="co">## X13         4.576675</span></a>
<a class="sourceLine" id="cb304-43" data-line-number="43"><span class="co">## X23         4.974290</span></a></code></pre></div>
<p>At this point the model is trained and the next step is to evaluate its usefulness at making predictions. Let’s see how the model does at predicting the labels of the test dataset. Remember that the test data was <em>not</em> used during the training exericse. As such, the confusion matrix and classification accuracy associated with the test dataset provides a useful check of the skill of the model. Add the <code>Part 4</code> code below to your RScript but omit lines that begin with a double-hash (<code>##</code>) :</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb305-1" data-line-number="1"><span class="co">#</span></a>
<a class="sourceLine" id="cb305-2" data-line-number="2"><span class="co"># Part 4 - evaluate the model using test data</span></a>
<a class="sourceLine" id="cb305-3" data-line-number="3"><span class="co">#</span></a>
<a class="sourceLine" id="cb305-4" data-line-number="4"></a>
<a class="sourceLine" id="cb305-5" data-line-number="5"><span class="co"># extract test predictions</span></a>
<a class="sourceLine" id="cb305-6" data-line-number="6">preds &lt;-<span class="st"> </span><span class="kw">predict</span>(model, test)</a>
<a class="sourceLine" id="cb305-7" data-line-number="7"></a>
<a class="sourceLine" id="cb305-8" data-line-number="8"><span class="co"># confusion matrix</span></a>
<a class="sourceLine" id="cb305-9" data-line-number="9">actual &lt;-<span class="st"> </span><span class="kw">factor</span>(test<span class="op">$</span>Y04)</a>
<a class="sourceLine" id="cb305-10" data-line-number="10">predicted &lt;-<span class="st"> </span><span class="kw">factor</span>(preds)</a>
<a class="sourceLine" id="cb305-11" data-line-number="11">common_levels &lt;-<span class="st"> </span><span class="kw">sort</span>(<span class="kw">unique</span>(<span class="kw">c</span>(<span class="kw">levels</span>(actual), <span class="kw">levels</span>(predicted))))</a>
<a class="sourceLine" id="cb305-12" data-line-number="12">actual &lt;-<span class="st"> </span><span class="kw">factor</span>(actual, <span class="dt">levels =</span> common_levels)</a>
<a class="sourceLine" id="cb305-13" data-line-number="13">predicted &lt;-<span class="st"> </span><span class="kw">factor</span>(predicted, <span class="dt">levels =</span> common_levels)</a>
<a class="sourceLine" id="cb305-14" data-line-number="14">confusion &lt;-<span class="st"> </span><span class="kw">table</span>(actual,predicted)</a>
<a class="sourceLine" id="cb305-15" data-line-number="15"><span class="kw">print</span>(confusion)</a>
<a class="sourceLine" id="cb305-16" data-line-number="16"><span class="co">##       predicted</span></a>
<a class="sourceLine" id="cb305-17" data-line-number="17"><span class="co">## actual 4 5 6 7</span></a>
<a class="sourceLine" id="cb305-18" data-line-number="18"><span class="co">##      4 0 1 1 0</span></a>
<a class="sourceLine" id="cb305-19" data-line-number="19"><span class="co">##      5 0 3 3 0</span></a>
<a class="sourceLine" id="cb305-20" data-line-number="20"><span class="co">##      6 0 1 2 0</span></a>
<a class="sourceLine" id="cb305-21" data-line-number="21"><span class="co">##      7 0 0 1 0</span></a>
<a class="sourceLine" id="cb305-22" data-line-number="22"></a>
<a class="sourceLine" id="cb305-23" data-line-number="23"><span class="co">#classification accuracy</span></a>
<a class="sourceLine" id="cb305-24" data-line-number="24">accuracy &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(confusion)<span class="op">/</span><span class="kw">nrow</span>(test))</a>
<a class="sourceLine" id="cb305-25" data-line-number="25"><span class="kw">cat</span>(<span class="st">&quot;Classification Accuracy = &quot;</span>, accuracy, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb305-26" data-line-number="26"><span class="co">## Classification Accuracy =  0.4166667</span></a></code></pre></div>
<p>Save your script and run it. Take a look at the results for the test dataset - the classifcation accuracy is well under 50%. Furthermore, there are systematic failures in the confusion matrix. It’s not a very good model. The most likely culprit is that the set of features is inadequate for making the desired prediction. We should re-run the model using different or additional features.</p>
</div>
</div>
<div id="day-23---support-vector-machines" class="section level2">
<h2><span class="header-section-number">4.2</span> Day 23 - Support Vector Machines</h2>
<p>For today’s independent work you will learn about the Support Support Vector Machine (SVM) algorithm and apply it to the COVID-19 data that you worked with on Monday.</p>
<p>The SVM algorithm seeks to determine an optimal hyperplane that separates labeled observations.</p>
<ul>
<li><p>Hyperplanes can be linear or non-linear.</p></li>
<li><p>Support vectors are data points lying closest to the optimal hyperplane.</p></li>
<li><p>The <code>e1071</code> package in R provides an implementation of SVM.</p></li>
</ul>
<p>The figure below illusrates a linear SVM. Line <span class="math inline">\(H_3\)</span> provides the optimal separation between the white and black data points. Points with perpendiculars to <span class="math inline">\(H_3\)</span> are the support vectors for the dataset. The SVM algorithm classifies unlabeled data points by examining their location with respect to the optimal hyperplane. Data points <em>above</em> line <span class="math inline">\(H_3\)</span> would be classified as “black” and datapoints <em>below</em> the line would be calssified as white.</p>
<p><img src="images/ml_svm_example.png" width="50%" style="display: block; margin: auto;" /></p>
<div id="an-svm-example-using-covid-19" class="section level3">
<h3><span class="header-section-number">4.2.1</span> An SVM Example using COVID-19</h3>
<p>We’ve already laid a large part of the groundwork for machine learning with the random forest example. With a few modifications, the <code>covid_19_rf.R</code> script can be adapted to use an SVM algorithm instead of Random Forest.</p>
<ul>
<li><p>Open your <code>covid_19_rf.R</code> script in <em>RStudio</em></p></li>
<li><p>Click <code>File --&gt; Save As ...</code> and name the file <code>covid_19_svm.R</code></p></li>
<li><p>In <code>Part 1</code> of <code>covid_19_svm.R</code>, replace <code>library(randomForest)</code> with <code>library(e1071)</code>. This will load the <code>svm</code> algorithm instead of the <code>randomForest</code> algorithm.</p></li>
<li><p>In <code>Part 3</code> of the code, replace <code>randomForest()</code> with <code>svm()</code> and add the following argument to the <code>svm()</code> function: <code>probability = TRUE</code>. The <code>svm()</code> code should look something like this:</p></li>
</ul>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb306-1" data-line-number="1">model &lt;-<span class="st"> </span><span class="kw">svm</span>(Y04 <span class="op">~</span><span class="st"> </span>X01 <span class="op">+</span><span class="st"> </span>X10 <span class="op">+</span><span class="st"> </span>X12 <span class="op">+</span><span class="st"> </span>X13 <span class="op">+</span><span class="st"> </span>X23, </a>
<a class="sourceLine" id="cb306-2" data-line-number="2">             <span class="dt">data =</span> train,</a>
<a class="sourceLine" id="cb306-3" data-line-number="3">             <span class="dt">probability =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<ul>
<li>The <code>svm()</code> package does not provide useful implementations of <code>print(model)</code> or <code>importance(model)</code>. Comment out, or delete, those lines of <code>Part 3</code> and replace with <code>summary(model)</code>. When you are finished, the final section of the <code>Part 3</code> code should look something like this:</li>
</ul>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb307-1" data-line-number="1"><span class="co"># show results, includes confusion matrix for training data</span></a>
<a class="sourceLine" id="cb307-2" data-line-number="2"><span class="co"># print(model) </span></a>
<a class="sourceLine" id="cb307-3" data-line-number="3"><span class="co">#</span></a>
<a class="sourceLine" id="cb307-4" data-line-number="4"><span class="co"># measure of parameter importance</span></a>
<a class="sourceLine" id="cb307-5" data-line-number="5"><span class="co"># importance(model) </span></a>
<a class="sourceLine" id="cb307-6" data-line-number="6"><span class="co">#</span></a>
<a class="sourceLine" id="cb307-7" data-line-number="7"><span class="co"># summarize the trained SVM</span></a>
<a class="sourceLine" id="cb307-8" data-line-number="8"><span class="kw">summary</span>(model)</a></code></pre></div>
<p>That’s it! The rest of the code (i.e. <code>Part 4</code>) can be re-used. Save your <code>covid_19_svm.R</code> script and run it. How does the SVM algorithm perform in comparison with the Random Forest algorithm?</p>
</div>
</div>
<div id="day-24---the-k-nearest-neighbors-algorithm" class="section level2">
<h2><span class="header-section-number">4.3</span> Day 24 - the <span class="math inline">\(k\)</span>-Nearest Neighbors Algorithm</h2>
<p>For today’s independent work you will learn about the <span class="math inline">\(k\)</span>-Nearest neighbors (KNN) algorithm and apply it to the COVID-19 data.</p>
<p>For a given unlabeled data point (<span class="math inline">\(X^*\)</span>) the KNN algorithm identifies the nearest <span class="math inline">\(k\)</span> labeled data points.</p>
<ul>
<li><p>Euclidean distance is typical</p></li>
<li><p><em>Normalization of data is necessary to prevent biased distances.</em></p></li>
<li><p>The label of <span class="math inline">\(X^*\)</span> is predicted to be the most frequently occurring label among the <span class="math inline">\(k\)</span> nearest neighbors.</p></li>
<li><p>The <code>class</code> package in R provides an implementation of KNN.</p></li>
</ul>
<p>The figure below illustrates the KNN approach and is courtesy of <a href="https://commons.wikimedia.org/wiki/File:KnnClassification.svg">Antti Ajanki</a>. For <span class="math inline">\(k=3\)</span>, the neighborhood contains 2 triangles and 1 square so we’d predict <span class="math inline">\(X^*\)</span> is a triangle. For <span class="math inline">\(k=5\)</span>, the neighborhood contains 3 squares and 2 triangles so we’d predict <span class="math inline">\(X^*\)</span> is a square.</p>
<p><img src="images/ml_knn_example.png" width="50%" style="display: block; margin: auto;" /></p>
<p>With a few modifications, the <code>covid_19_svm.R</code> script can be adapted to use an KNN algorithm instead of SVM.</p>
<ul>
<li><p>Open your <code>covid_19_svm.R</code> script in <em>RStudio</em></p></li>
<li><p>Click <code>File --&gt; Save As ...</code> and name the file <code>covid_19_knn.R</code></p></li>
<li><p>In <code>Part 1</code> of <code>covid_19_knn.R</code>, replace <code>library(e1071)</code> with <code>library(class)</code>. This will load the <code>knn</code> algorithm instead of the <code>svm</code> algorithm.</p></li>
<li><p>The KNN algorithm requires the feature data to be normalized. Add the following line in <code>Part 1</code> of <code>covid_19_knn.R</code>. Add the line in between the <code>df$Y04 &lt;- as.factor(df$Y04)</code> line and the <code>df</code> line. If necessary, use <code>install.packages('BBmisc')</code> to install the <code>BBmisc</code> package and its <code>normalize()</code> function.</p></li>
</ul>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb308-1" data-line-number="1">df &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(Y04 &lt;-<span class="st"> </span><span class="kw">as.factor</span>(Y04))</a>
<a class="sourceLine" id="cb308-2" data-line-number="2">df &lt;-<span class="st"> </span>BBmisc<span class="op">::</span><span class="kw">normalize</span>(df, <span class="dt">method =</span> <span class="st">&quot;range&quot;</span>) <span class="co"># add this line</span></a>
<a class="sourceLine" id="cb308-3" data-line-number="3">df</a></code></pre></div>
<ul>
<li>In <code>Part 3</code> of the code, replace <code>svm()</code> with <code>knn()</code> and adjust the call to <code>knn()</code> so that it looks like this:</li>
</ul>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb309-1" data-line-number="1">model &lt;-<span class="st"> </span><span class="kw">knn</span>(<span class="kw">select</span>(train, <span class="kw">all_of</span>(my_x)),</a>
<a class="sourceLine" id="cb309-2" data-line-number="2">             <span class="kw">select</span>(test, <span class="kw">all_of</span>(my_x)),</a>
<a class="sourceLine" id="cb309-3" data-line-number="3">             train<span class="op">$</span>Y04,</a>
<a class="sourceLine" id="cb309-4" data-line-number="4">             <span class="dt">k =</span> <span class="dv">7</span>,</a>
<a class="sourceLine" id="cb309-5" data-line-number="5">             <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<ul>
<li>The <code>knn()</code> package does not provide useful implementations <code>print(model)</code>, <code>importance(model)</code>, or <code>summary(model)</code>. Comment out, or delete, those lines of <code>Part 3</code>. When you are finished, the final section of the <code>Part 3</code> code should look something like this:</li>
</ul>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb310-1" data-line-number="1"><span class="co"># show results, includes confusion matrix for training data</span></a>
<a class="sourceLine" id="cb310-2" data-line-number="2"><span class="co"># print(model) </span></a>
<a class="sourceLine" id="cb310-3" data-line-number="3"><span class="co">#</span></a>
<a class="sourceLine" id="cb310-4" data-line-number="4"><span class="co"># measure of parameter importance</span></a>
<a class="sourceLine" id="cb310-5" data-line-number="5"><span class="co"># importance(model) </span></a>
<a class="sourceLine" id="cb310-6" data-line-number="6"><span class="co">#</span></a>
<a class="sourceLine" id="cb310-7" data-line-number="7"><span class="co"># summarize the trained SVM</span></a>
<a class="sourceLine" id="cb310-8" data-line-number="8"><span class="co"># summary(model)</span></a></code></pre></div>
<ul>
<li>In <code>Part 4</code> of the script, replace:</li>
</ul>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb311-1" data-line-number="1">preds &lt;-<span class="st"> </span><span class="kw">predict</span>(model, test)</a></code></pre></div>
<p>with:</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb312-1" data-line-number="1">preds &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(model)[,<span class="dv">1</span>]</a></code></pre></div>
<p>That’s it! The rest of the code can be re-used. Save your <code>covid_19_knn.R</code> script and run it. How does the KNN algorithm perform in comparison with the Random Forest and SVM algorithms?</p>
</div>
<div id="day-25---artificial-neural-networks" class="section level2">
<h2><span class="header-section-number">4.4</span> Day 25 - Artificial Neural Networks</h2>
<p>For today’s independent work you will learn about artificial neural networks (ANN). You will attempt to add Keras and TensorFlow support to your R/RStudio installation. If this is successful, you can apply an ANN to the COVID-19 example that you’ve been working with during the week.</p>
<div id="introduction-to-artifical-neural-networks" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Introduction to Artifical Neural Networks</h3>
<p>Artificial Neural Networks (ANN) are made of an input layer, an output layer, and one or more “hidden”
layers. A simple “shallow” ANN is illustrated in the following figure:</p>
<p><img src="images/ml_ann_shallow.png" width="50%" style="display: block; margin: auto;" /></p>
<p>The figure highlights some interesting ANN features:</p>
<ul>
<li><p>Each layer contains one or more neurons and these are represented as circles in the figure.</p></li>
<li><p>The first layer is call the <em>input</em> layer and the number of neurons in this layer is matched to the number of features in the data set.</p></li>
<li><p>The last layer is called the <em>output</em> layer. The number of neurons in the output layer is equal to the number of categories that the ANN is trying to predict. For example, there would be 2 neurons in the output layer if you were trying to predict gender (male vs. female). The output of each neuron in the output layer represents the probability or likelihood of a given category (e.g. Pr(male) vs. Pr(female)).</p></li>
<li><p>Intermediate layers are called <em>hidden</em> layers. Hidden layers can have more or less neurons than the input and output layers.</p></li>
<li><p>Each neuron produces a weighted combination of its inputs and passes the results to neurons in the next layer.</p></li>
<li><p>Weights (<span class="math inline">\(w_i\)</span>) are adjusted to develop an optimal mapping between inputs (<span class="math inline">\(x_i\)</span>) and outputs (<span class="math inline">\(y_i\)</span>).</p></li>
</ul>
<div id="deep-neural-networks" class="section level4 unnumbered">
<h4>Deep Neural Networks</h4>
<p>The advent of faster processors and accelerators like <a href="https://www.nvidia.com/en-us/deep-learning-ai/developer/">NVIDIA’s GPUs</a> and <a href="https://cloud.google.com/blog/products/ai-machine-learning/what-makes-tpus-fine-tuned-for-deep-learning">Google’s TPUs</a> has made it possible to construct and train ANNs that have more and more hidden layers. Such networks are often referred to as “deep neural networks”. The corresponding modeling process has been dubbed “deep learning” to distinguish it from conventional machine learning approaches like random forests, support vector machines, and k-Nearest neighbors.</p>
<p>The figure below illustrates a “fully connected” (i.e. all neurons in adjacent layers are connected) deep neural network.</p>
<p><img src="images/ml_ann_deep.png" width="50%" style="display: block; margin: auto;" /></p>
<ul>
<li><p>The increased number of layers yields an extremely large number of connections.</p></li>
<li><p>More connections allows the neural network to consider massive numbers of input combinations.</p></li>
<li><p>More combinations means more weights that need to be trained.</p></li>
<li><p>Calibrating so many weights requires an increasingly large training data set.</p></li>
</ul>
<p>Nowadays, the biggest challenge for applying deep learning is not computational resources but rather data scarcity.</p>
</div>
</div>
<div id="keras-and-tensorflow" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Keras and TensorFlow</h3>
<p>TensorFlow is a very popular set of deep learning tools that was developed by Google and made Open Source in 2015. TensorFlow is capable of exploiting GPU acceleration and can solve a wide variety of complex ANNs. The figure below illustrates the various layers of TensorFlow.</p>
<ul>
<li><p>At the lowest level is the kernel. The kernel is responsible for solving an ANN in the most efficient manner using all of the resources (e.g. CPUs, GPUS, TPUs, etc.) that a given TensorFlow installation has at its disposal.</p></li>
<li><p>The remaining layers consist of various programming interfaces. We’ll actually be using an interface called Keras.</p></li>
<li><p>The “native” programming language for TensorFlow is Python version 3.x and TensorFlow is conveniently deployed via the Anaconda Python distribution. So you will need to install Anaconda Python as a pre-requisite for using TensorFlow - details are provided below.</p></li>
</ul>
<p><img src="images/ml_tflow_api.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Keras is an application programming interface (API) for TensorFlow. Keras is now bundled with TensorFlow - so Keras will be installed automatically if/when you install TensorFlow.</p>
<p>Keras makes it easier to assemble and train complicated train complicated neural networks. Examples include: convolutional neural networks, recurrent neural networks, generative adversarial neural networks, and autoencoders. With Keras you can:</p>
<ul>
<li><p>Easily translate complex multi-layered ANN diagrams into the corresponding Keras code.</p></li>
<li><p>Select loss functions and optimizers from a large built-in library.</p></li>
<li><p>Include a variety of pre-defined <a href="https://keras.io/layers/core/">layer types</a>, including:</p>
<ul>
<li><p>dense (i.e. fully connected) layers</p></li>
<li><p>embedding, pooling and dropout layers</p></li>
<li><p>cropping, padding and flattening layers</p></li>
<li><p>1D/2D/3D convolutional layers</p></li>
<li><p>long short term memory (LSTM) layers</p></li>
<li><p>many more!</p></li>
</ul></li>
</ul>
<div id="installing-keras-and-tensorflow" class="section level4 unnumbered">
<h4>Installing Keras and TensorFlow</h4>
<p>A pre-requisite for using Keras and TensorFlow is to install Anaconda Python version 3.x: <a href="https://www.anaconda.com/download" class="uri">https://www.anaconda.com/download</a></p>
<p>Instructions for installing Keras and TensorFlow for use within RStudio are provided at <a href="https://keras.rstudio.com/" class="uri">https://keras.rstudio.com/</a> and these are repeated below. The installation of Anaconda Python and Keras can take a while and may require restarting <em>RStudio</em>. It is a good idea to save and close any open <em>RStudio</em> sessions before attempting these installations.</p>
<p><em>Option #1</em> (suggested by <a href="https://keras.rstudio.com" class="uri">https://keras.rstudio.com</a> )</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb313-1" data-line-number="1"><span class="kw">install.packages</span>(<span class="st">&quot;devtools&quot;</span>)</a>
<a class="sourceLine" id="cb313-2" data-line-number="2">devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;rstudio/keras&quot;</span>)</a>
<a class="sourceLine" id="cb313-3" data-line-number="3"><span class="kw">library</span>(keras)</a>
<a class="sourceLine" id="cb313-4" data-line-number="4"><span class="kw">install_keras</span>()</a></code></pre></div>
<p><em>Option #2</em> (if option #1 fails)</p>
<ul>
<li>Step 1: Use <code>conda</code> to install TensorFlow (and Keras, too) from a system prompt (e.g. <code>DOS</code> on Windows machines). On Windows, you may need to choose “run as admin” when launching the <code>DOS</code> prompt.</li>
</ul>
<pre><code>[DOS]&gt; activate r-reticulate
(r-reticulate)[DOS]&gt; conda remove  tensorflow
(r-reticulate)[DOS]&gt; conda install tensorflow</code></pre>
<ul>
<li>Step 2: Use the short form package installations in <em>RStudio</em> (i.e. skip <code>install_keras()</code> and <code>install_tensorflow()</code>):</li>
</ul>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb315-1" data-line-number="1"><span class="co"># re-install tensorflow</span></a>
<a class="sourceLine" id="cb315-2" data-line-number="2"><span class="kw">install.packages</span>(<span class="st">&quot;tensorflow&quot;</span>)</a>
<a class="sourceLine" id="cb315-3" data-line-number="3"></a>
<a class="sourceLine" id="cb315-4" data-line-number="4"><span class="co"># check tensorflow installation</span></a>
<a class="sourceLine" id="cb315-5" data-line-number="5"><span class="kw">library</span>(tensorflow)</a>
<a class="sourceLine" id="cb315-6" data-line-number="6"><span class="kw">Sys.setenv</span>(<span class="dt">HDF5_DISABLE_VERSION_CHECK =</span> <span class="st">&quot;2&quot;</span>)</a>
<a class="sourceLine" id="cb315-7" data-line-number="7">tf<span class="op">$</span><span class="kw">constant</span>(<span class="st">&quot;Hello from Tensorflow&quot;</span>)</a>
<a class="sourceLine" id="cb315-8" data-line-number="8"></a>
<a class="sourceLine" id="cb315-9" data-line-number="9"><span class="co"># re-install keras</span></a>
<a class="sourceLine" id="cb315-10" data-line-number="10">devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;rstudio/keras&quot;</span>)</a>
<a class="sourceLine" id="cb315-11" data-line-number="11"></a>
<a class="sourceLine" id="cb315-12" data-line-number="12"><span class="co"># check keras installation</span></a>
<a class="sourceLine" id="cb315-13" data-line-number="13"><span class="kw">library</span>(keras)</a>
<a class="sourceLine" id="cb315-14" data-line-number="14"><span class="kw">to_categorical</span>(<span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">4</span>),<span class="dv">5</span>)</a></code></pre></div>
</div>
</div>
<div id="applying-keras-and-tensorflow-to-the-covid-19-dataset" class="section level3">
<h3><span class="header-section-number">4.4.3</span> Applying Keras and TensorFlow to the COVID-19 Dataset</h3>
<p>Give yourself a big pat on the back if you’ve successfully completed the Keras installation! If you run into trouble please post on the Teams chat and hopefully someone can help you out.</p>
<p>To apply Keras to the COVID-19 dataset, we’ll adapt a copy of the <code>covid_19_knn.R</code> script.</p>
<ul>
<li><p>In <em>RStudio</em>, open <code>covid_19_knn.R</code> and save it as <code>covid_19_keras.R</code></p></li>
<li><p>In <code>Part 1</code> of the <code>covid_19_keras.R</code> file, replace <code>library(class)</code> with <code>library(keras)</code>. This will adjust the script to use the Keras API instead of the KNN algorithm.</p></li>
<li><p>In <code>Part 3</code> of the script, insert the following code in between the sections that split the data and create the model.</p></li>
</ul>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb316-1" data-line-number="1"></a>
<a class="sourceLine" id="cb316-2" data-line-number="2"><span class="co"># split into train (75%) and test (25%) datasets</span></a>
<a class="sourceLine" id="cb316-3" data-line-number="3"><span class="co"># .</span></a>
<a class="sourceLine" id="cb316-4" data-line-number="4"><span class="co"># .</span></a>
<a class="sourceLine" id="cb316-5" data-line-number="5"><span class="co"># .</span></a>
<a class="sourceLine" id="cb316-6" data-line-number="6"></a>
<a class="sourceLine" id="cb316-7" data-line-number="7"><span class="co"># ----- insert the following code -----</span></a>
<a class="sourceLine" id="cb316-8" data-line-number="8"><span class="co"># manipulate dataset into Keras format</span></a>
<a class="sourceLine" id="cb316-9" data-line-number="9">x_train &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">select</span>(train, <span class="kw">all_of</span>(my_x)))</a>
<a class="sourceLine" id="cb316-10" data-line-number="10">y_train &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">select</span>(train, <span class="kw">all_of</span>(my_y)), as.character)</a>
<a class="sourceLine" id="cb316-11" data-line-number="11">y_train &lt;-<span class="st"> </span><span class="kw">as.integer</span>(y_train)</a>
<a class="sourceLine" id="cb316-12" data-line-number="12"></a>
<a class="sourceLine" id="cb316-13" data-line-number="13">x_test  &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">select</span>(test, <span class="kw">all_of</span>(my_x)))</a>
<a class="sourceLine" id="cb316-14" data-line-number="14">y_test  &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">select</span>(test, <span class="kw">all_of</span>(my_y)), as.character)</a>
<a class="sourceLine" id="cb316-15" data-line-number="15">y_test  &lt;-<span class="st"> </span><span class="kw">as.integer</span>(y_test)</a>
<a class="sourceLine" id="cb316-16" data-line-number="16"></a>
<a class="sourceLine" id="cb316-17" data-line-number="17">y_min   &lt;-<span class="st"> </span><span class="kw">min</span>(y_train,y_test)</a>
<a class="sourceLine" id="cb316-18" data-line-number="18">y_train &lt;-<span class="st"> </span>y_train <span class="op">-</span><span class="st"> </span>y_min</a>
<a class="sourceLine" id="cb316-19" data-line-number="19">y_test  &lt;-<span class="st"> </span>y_test  <span class="op">-</span><span class="st"> </span>y_min</a>
<a class="sourceLine" id="cb316-20" data-line-number="20"></a>
<a class="sourceLine" id="cb316-21" data-line-number="21"><span class="co"># one-hot encoding</span></a>
<a class="sourceLine" id="cb316-22" data-line-number="22">n_classes &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">levels</span>(df<span class="op">$</span>Y04))</a>
<a class="sourceLine" id="cb316-23" data-line-number="23">y_train &lt;-<span class="st"> </span><span class="kw">to_categorical</span>(y_train, n_classes)</a>
<a class="sourceLine" id="cb316-24" data-line-number="24">y_test  &lt;-<span class="st"> </span><span class="kw">to_categorical</span>(y_test, n_classes)</a>
<a class="sourceLine" id="cb316-25" data-line-number="25"></a>
<a class="sourceLine" id="cb316-26" data-line-number="26"><span class="co"># assign hyperparameters</span></a>
<a class="sourceLine" id="cb316-27" data-line-number="27">num_epochs &lt;-<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb316-28" data-line-number="28">num_batch &lt;-<span class="st"> </span><span class="dv">25</span></a>
<a class="sourceLine" id="cb316-29" data-line-number="29">val_split &lt;-<span class="st"> </span><span class="fl">0.2</span></a>
<a class="sourceLine" id="cb316-30" data-line-number="30"></a>
<a class="sourceLine" id="cb316-31" data-line-number="31"><span class="co"># ----- end of code instertion -----            </span></a>
<a class="sourceLine" id="cb316-32" data-line-number="32"></a>
<a class="sourceLine" id="cb316-33" data-line-number="33"><span class="co"># create and train the KNN model</span></a>
<a class="sourceLine" id="cb316-34" data-line-number="34"><span class="co"># .</span></a>
<a class="sourceLine" id="cb316-35" data-line-number="35"><span class="co"># .</span></a>
<a class="sourceLine" id="cb316-36" data-line-number="36"><span class="co"># .</span></a></code></pre></div>
<p>The previous bit of code prepares the data set for use by Keras:</p>
<ul>
<li><p>Keras wants <em>X</em> (features) and <em>Y</em> (labels) separated.</p></li>
<li><p>Keras wants features represented as matrices.</p></li>
<li><p>Keras wants labels represented as 0-based integers that are “one-hot” encoded. The figure below illustrates integer and one-hot encoding of a set of animal categories. In the figure, <code>Pr()</code> represents the probability of a given category.</p></li>
</ul>
<p><img src="images/ml_one_hot_encoding.png" width="50%" style="display: block; margin: auto;" /></p>
<p>The code segment given above also sets up some algorithm parameters for the ANN:</p>
<ul>
<li><p><code>num_epochs</code>: The number of training steps. At each training step, an optimizer refines the network weights to improve predictions associated with a randomly sampled subset (i.e. batch) of the training data.</p></li>
<li><p><code>num_batch</code>: The size of the randomly sampled subset of the training data that is used in each training epoch.</p></li>
<li><p><code>val_split</code>&quot; The validation split is a float between 0 and 1. It is the fraction of the training data to be used as validation data. The model will set apart this fraction of the training data (i.e. it will not train on it). The model will evaluate the loss and other metrics on this data at the end of each epoch.</p></li>
</ul>
<p>The next step in adapting the KNN example to use Keras is to replace the “create and train” portion.</p>
<p>Replace:</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb317-1" data-line-number="1"><span class="co"># create and train the KNN model</span></a>
<a class="sourceLine" id="cb317-2" data-line-number="2">model &lt;-<span class="st"> </span><span class="kw">knn</span>(<span class="kw">select</span>(train, <span class="kw">all_of</span>(my_x)),</a>
<a class="sourceLine" id="cb317-3" data-line-number="3">             <span class="kw">select</span>(test, <span class="kw">all_of</span>(my_x)),</a>
<a class="sourceLine" id="cb317-4" data-line-number="4">             train<span class="op">$</span>Y04,</a>
<a class="sourceLine" id="cb317-5" data-line-number="5">             <span class="dt">k =</span> <span class="dv">7</span>,</a>
<a class="sourceLine" id="cb317-6" data-line-number="6">             <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p>With:</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb318-1" data-line-number="1">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</a>
<a class="sourceLine" id="cb318-2" data-line-number="2">n_inputs &lt;-<span class="st"> </span><span class="kw">ncol</span>(x_train)</a>
<a class="sourceLine" id="cb318-3" data-line-number="3"><span class="co"># input layer</span></a>
<a class="sourceLine" id="cb318-4" data-line-number="4"><span class="kw">layer_dense</span>(model, <span class="dt">units =</span> <span class="dv">20</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>, <span class="dt">input_shape =</span> <span class="kw">c</span>(n_inputs))</a>
<a class="sourceLine" id="cb318-5" data-line-number="5"><span class="co"># hidden layer</span></a>
<a class="sourceLine" id="cb318-6" data-line-number="6"><span class="kw">layer_dense</span>(model, <span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>)</a>
<a class="sourceLine" id="cb318-7" data-line-number="7"><span class="co"># output layer</span></a>
<a class="sourceLine" id="cb318-8" data-line-number="8"><span class="kw">layer_dense</span>(model, <span class="dt">units =</span> n_classes, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>)</a>
<a class="sourceLine" id="cb318-9" data-line-number="9"><span class="co"># display nework architecture</span></a>
<a class="sourceLine" id="cb318-10" data-line-number="10"><span class="kw">summary</span>(model)</a>
<a class="sourceLine" id="cb318-11" data-line-number="11"><span class="co"># assign loss function and optimizer</span></a>
<a class="sourceLine" id="cb318-12" data-line-number="12"><span class="kw">compile</span>(model, </a>
<a class="sourceLine" id="cb318-13" data-line-number="13">        <span class="dt">loss =</span> <span class="st">&quot;categorical_crossentropy&quot;</span>,</a>
<a class="sourceLine" id="cb318-14" data-line-number="14">        <span class="dt">optimizer =</span> <span class="kw">optimizer_rmsprop</span>(),</a>
<a class="sourceLine" id="cb318-15" data-line-number="15">        <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">&#39;accuracy&#39;</span>))</a>
<a class="sourceLine" id="cb318-16" data-line-number="16"><span class="co"># train the model</span></a>
<a class="sourceLine" id="cb318-17" data-line-number="17">results &lt;-<span class="st"> </span><span class="kw">fit</span>(model,</a>
<a class="sourceLine" id="cb318-18" data-line-number="18">               x_train, y_train,</a>
<a class="sourceLine" id="cb318-19" data-line-number="19">               <span class="dt">epochs =</span> num_epochs,</a>
<a class="sourceLine" id="cb318-20" data-line-number="20">               <span class="dt">batch_size =</span> num_batch,</a>
<a class="sourceLine" id="cb318-21" data-line-number="21">               <span class="dt">validation_split =</span> val_split)</a>
<a class="sourceLine" id="cb318-22" data-line-number="22"><span class="co"># examine convergence progress</span></a>
<a class="sourceLine" id="cb318-23" data-line-number="23"><span class="kw">plot</span>(results)</a>
<a class="sourceLine" id="cb318-24" data-line-number="24">results</a></code></pre></div>
<p>This is a simple fully-connected shallow neural network. It is configured to use “categorical cross-entropy” as the loss function. The loss function is a measure of how closely the model outputs match with the actual labels in the training data. The figure below illustrates the steps involved in calculating the loss function. The <code>optimizer</code> field specifies an algorithm for minimizing the loss function. The <code>rmsprop</code> optimizer is an implementation of the “<u>R</u>oot <u>M</u>ean <u>S</u>quared <u>prop</u>agation” method. It is a fast and effective gradient-based procedure that is a good default choice for classification problems.</p>
<p><img src="images/ml_loss_function.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Make sure your plot window has some room; then highlight the portion of ANN script that you’ve adapted so far and run it. You should eventually see pair of plots similar to the figure below. These plots provide an epoch-by-epoch trace of the accuracy and loss for both the training and validation data. Watch out for cases of “overfitting” - where the training performance improves but the validation performance degrades.</p>
<p><img src="images/Rplot_ann_convergence.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The final step in modifying the KNN script for use with Keras is the computation of the classification accuracy and confusion matrix (i.e <code>Part 4</code>). Only the the <code>preds</code> assignment needs to be changed:</p>
<p>Replace:</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb319-1" data-line-number="1">preds &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(model)[,<span class="dv">1</span>]</a></code></pre></div>
<p>With:</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb320-1" data-line-number="1">preds &lt;-<span class="st"> </span><span class="kw">predict_classes</span>(model, x_test) <span class="op">+</span><span class="st"> </span>y_min</a></code></pre></div>
<p>Highlight and run the <code>Part 4</code> code to check the skill of the model at predicting the test data. How do the results compare to the random forest, support vector machine, and k-nearest neighbors algorithms?</p>
</div>
</div>
<div id="day-26-friday-zoom-check-in" class="section level2">
<h2><span class="header-section-number">4.5</span> Day 26 (Friday) Zoom check-in</h2>
<p>Today we’ll check how you’re doing with using machine learning in <em>R</em>. Then we’ll get you prepared for weekend activities, where you’ll continue to explore modeling using the COVID-19 dataset.</p>
<div id="review-and-trouble-shoot-25-minutes" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Review and trouble shoot (25 minutes)</h3>
<ul>
<li><p>Has everyone had a chance to try out at least one of the machine learning algorithms?</p></li>
<li><p>Has anyone tried additional or alternative combinations of features?</p></li>
<li><p>What is the best classification accuracy that you have been able to obtain?</p></li>
<li><p>What parameters appear to be the most important?</p></li>
<li><p>Has anyone attempted the Keras/TensorFlow example? How did that go?</p></li>
</ul>
</div>
<div id="this-weekend-25-minutes" class="section level3">
<h3><span class="header-section-number">4.5.2</span> This weekend (25 minutes)</h3>
<div id="rocauc---another-measure-of-machine-learning-performance" class="section level4 unnumbered">
<h4>ROC/AUC - Another Measure of Machine Learning Performance</h4>
<p>We’ve already seen how classification accuracy and the confusion matrix give an indication of the performance of a trained machine learning algorithm. It’s also good practice to examine the “ROC curve” and related “AUC” metrics.</p>
<ul>
<li><em>ROC curve</em>: As illustrated in the figure below, the ROC (Receiver Operating Characteristic) curve plots the true positive (TP) vs. false positive (FP) rate at various probability thresholds. In the figure, the dashed blue line represents a hypothetical ROC curve for some machine learning model and the solid red line is the curve for a “non-informative” model (i.e. a model that makes a uniform random guess). As such, we’d like the blue curve to be as far above the red curve as possible.</li>
</ul>
<p><img src="images/ml_roc_curve_example.png" width="75%" style="display: block; margin: auto;" /></p>
<ul>
<li><p><em>AUC</em>: AUC stands for “area under curve” and is the area under the ROC curve. In the previous figure, the AUC would be the area under the dashed blue curve. Values of AUC quantify the degree to which an ROC curve lies above (or below) the “non-informative” curve. Some interesting AUC values:</p>
<ul>
<li><p>AUC = 0.0: the model is always wrong (with respect to TP vs. FP)</p></li>
<li><p>AUC = 0.5: the model is no better than guessing (i.e. the model matches the red “non-informative” curve in the figure)</p></li>
<li><p>AUC = 1.0: the model is always right (with respect to TP vs. FP)</p></li>
</ul></li>
</ul>
<p>For a problem with multiple classes (as opposed to a binary True/False, Male/Female, or Yes/No problem) we can compute the ROC curve curve and AUC measures using a “one vs. all” approach:</p>
<ul>
<li><p>First, extract predicted probabilities from the RF model (the scores).</p></li>
<li><p>Next, extract actual classification for each category.</p></li>
<li><p>Finally, leverage three commands of the <code>ROCR</code> module:</p>
<ul>
<li><p><code>prediction()</code>: retrieve scores</p></li>
<li><p><code>performance()</code>: generates TPR, FPR, and AUC measures through two separate calls</p></li>
<li><p><code>print()</code>: generates a TPR vs. FPR plot</p></li>
</ul></li>
</ul>
<p>The ROC/AUC calculation is fairly involved so we’ll create a helper function for it and then incorporate the helper function into our machine learning scripts.</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb321-1" data-line-number="1"><span class="co">#</span></a>
<a class="sourceLine" id="cb321-2" data-line-number="2"><span class="co"># Part 5 - ROC/AUC</span></a>
<a class="sourceLine" id="cb321-3" data-line-number="3"><span class="co">#</span></a>
<a class="sourceLine" id="cb321-4" data-line-number="4"></a>
<a class="sourceLine" id="cb321-5" data-line-number="5"><span class="co"># roc_one_vs_all()</span></a>
<a class="sourceLine" id="cb321-6" data-line-number="6"><span class="co">#   A helper function to compute one vs. all ROC/AUC for a given level (i)</span></a>
<a class="sourceLine" id="cb321-7" data-line-number="7">roc_one_vs_all &lt;-<span class="st"> </span><span class="cf">function</span>(i) {</a>
<a class="sourceLine" id="cb321-8" data-line-number="8">    <span class="cf">if</span>(<span class="kw">is.na</span>(<span class="kw">sum</span>(probs))){</a>
<a class="sourceLine" id="cb321-9" data-line-number="9">        <span class="kw">return</span>(<span class="ot">NA</span>)</a>
<a class="sourceLine" id="cb321-10" data-line-number="10">    }</a>
<a class="sourceLine" id="cb321-11" data-line-number="11">    </a>
<a class="sourceLine" id="cb321-12" data-line-number="12">    actual &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(y_test[[<span class="dv">1</span>]] <span class="op">==</span><span class="st"> </span>i)</a>
<a class="sourceLine" id="cb321-13" data-line-number="13">    score &lt;-<span class="st"> </span>probs[,i]</a>
<a class="sourceLine" id="cb321-14" data-line-number="14">    </a>
<a class="sourceLine" id="cb321-15" data-line-number="15">    pred &lt;-<span class="st"> </span>ROCR<span class="op">::</span><span class="kw">prediction</span>(score, actual)</a>
<a class="sourceLine" id="cb321-16" data-line-number="16">    perf &lt;-<span class="st"> </span>ROCR<span class="op">::</span><span class="kw">performance</span>(pred, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>)</a>
<a class="sourceLine" id="cb321-17" data-line-number="17">    </a>
<a class="sourceLine" id="cb321-18" data-line-number="18">    ROCR<span class="op">::</span><span class="kw">plot</span>(perf, </a>
<a class="sourceLine" id="cb321-19" data-line-number="19">         <span class="dt">main=</span><span class="st">&quot;ROC Curve&quot;</span>, </a>
<a class="sourceLine" id="cb321-20" data-line-number="20">         <span class="dt">col=</span>cols[<span class="kw">as.numeric</span>(i)], </a>
<a class="sourceLine" id="cb321-21" data-line-number="21">         <span class="dt">add =</span> i <span class="op">!=</span><span class="st"> </span>lvls[[<span class="dv">1</span>]])</a>
<a class="sourceLine" id="cb321-22" data-line-number="22">    </a>
<a class="sourceLine" id="cb321-23" data-line-number="23">    <span class="co"># calculate the AUC and print</span></a>
<a class="sourceLine" id="cb321-24" data-line-number="24">    auc_i &lt;-<span class="st"> </span>ROCR<span class="op">::</span><span class="kw">performance</span>(pred, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)</a>
<a class="sourceLine" id="cb321-25" data-line-number="25">    <span class="kw">as.numeric</span>(auc_i<span class="op">@</span>y.values)</a>
<a class="sourceLine" id="cb321-26" data-line-number="26">}</a>
<a class="sourceLine" id="cb321-27" data-line-number="27"></a>
<a class="sourceLine" id="cb321-28" data-line-number="28"><span class="co"># prepare data for computing ROC/AUC</span></a>
<a class="sourceLine" id="cb321-29" data-line-number="29">x_test &lt;-<span class="st"> </span><span class="kw">select</span>(test, <span class="kw">all_of</span>(my_x))</a>
<a class="sourceLine" id="cb321-30" data-line-number="30">y_test &lt;-<span class="st"> </span><span class="kw">select</span>(test, <span class="kw">all_of</span>(my_y))</a>
<a class="sourceLine" id="cb321-31" data-line-number="31"><span class="co"># how we obtain probs depends on the algorithm</span></a>
<a class="sourceLine" id="cb321-32" data-line-number="32"><span class="cf">if</span> (<span class="kw">inherits</span>(model, <span class="st">&quot;randomForest&quot;</span>)) </a>
<a class="sourceLine" id="cb321-33" data-line-number="33">{</a>
<a class="sourceLine" id="cb321-34" data-line-number="34">    probs &lt;-<span class="st"> </span><span class="kw">predict</span>(model, x_test, <span class="dt">type=</span><span class="st">&#39;prob&#39;</span>)</a>
<a class="sourceLine" id="cb321-35" data-line-number="35">} <span class="cf">else</span> <span class="cf">if</span> (<span class="kw">inherits</span>(model, <span class="st">&quot;svm&quot;</span>))</a>
<a class="sourceLine" id="cb321-36" data-line-number="36">{</a>
<a class="sourceLine" id="cb321-37" data-line-number="37">    probs &lt;-<span class="st"> </span><span class="kw">predict</span>(model, x_test, <span class="dt">probability =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb321-38" data-line-number="38">    probs &lt;-<span class="st"> </span><span class="kw">attributes</span>(probs)</a>
<a class="sourceLine" id="cb321-39" data-line-number="39">    probs &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(probs<span class="op">$</span>probabilities)</a>
<a class="sourceLine" id="cb321-40" data-line-number="40">    probs &lt;-<span class="st"> </span>probs[,<span class="kw">order</span>(<span class="kw">colnames</span>(probs))]</a>
<a class="sourceLine" id="cb321-41" data-line-number="41">} <span class="cf">else</span> <span class="cf">if</span> (<span class="kw">inherits</span>(model,<span class="st">&quot;keras.engine.sequential.Sequential&quot;</span>))</a>
<a class="sourceLine" id="cb321-42" data-line-number="42">{</a>
<a class="sourceLine" id="cb321-43" data-line-number="43">    x_test &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">select</span>(test, <span class="kw">all_of</span>(my_x)))</a>
<a class="sourceLine" id="cb321-44" data-line-number="44">    probs &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">predict</span>(model, x_test))</a>
<a class="sourceLine" id="cb321-45" data-line-number="45">    <span class="kw">colnames</span>(probs) &lt;-<span class="st"> </span><span class="kw">levels</span>(df<span class="op">$</span>Y04)</a>
<a class="sourceLine" id="cb321-46" data-line-number="46">} <span class="cf">else</span> <span class="co"># the KNN alg requires approximation of probabilities</span></a>
<a class="sourceLine" id="cb321-47" data-line-number="47">{</a>
<a class="sourceLine" id="cb321-48" data-line-number="48">  <span class="co"># highest predicted probabilities</span></a>
<a class="sourceLine" id="cb321-49" data-line-number="49">  pnrst &lt;-<span class="st"> </span><span class="kw">attributes</span>(model)<span class="op">$</span>prob</a>
<a class="sourceLine" id="cb321-50" data-line-number="50">  <span class="co"># corresponding one-based categories</span></a>
<a class="sourceLine" id="cb321-51" data-line-number="51">  y_one &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">min</span>(<span class="kw">levels</span>(df<span class="op">$</span>Y04))) <span class="op">-</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb321-52" data-line-number="52">  vpreds &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">as.character</span>(preds)) <span class="op">-</span><span class="st"> </span>y_one</a>
<a class="sourceLine" id="cb321-53" data-line-number="53">  <span class="co"># map probabilities into a matrix of zeroes</span></a>
<a class="sourceLine" id="cb321-54" data-line-number="54">  probs &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="fl">0.00</span>, </a>
<a class="sourceLine" id="cb321-55" data-line-number="55">                  <span class="dt">nrow =</span> <span class="kw">length</span>(pnrst),</a>
<a class="sourceLine" id="cb321-56" data-line-number="56">                  <span class="dt">ncol =</span> <span class="kw">length</span>(<span class="kw">levels</span>(df<span class="op">$</span>Y04)))</a>
<a class="sourceLine" id="cb321-57" data-line-number="57">  probs[<span class="kw">cbind</span>(<span class="kw">seq_along</span>(vpreds), vpreds)] &lt;-<span class="st"> </span>pnrst</a>
<a class="sourceLine" id="cb321-58" data-line-number="58">  <span class="co"># coerce to data frame</span></a>
<a class="sourceLine" id="cb321-59" data-line-number="59">  probs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(probs)</a>
<a class="sourceLine" id="cb321-60" data-line-number="60">  <span class="kw">colnames</span>(probs) &lt;-<span class="st"> </span><span class="kw">levels</span>(df<span class="op">$</span>Y04)</a>
<a class="sourceLine" id="cb321-61" data-line-number="61">}</a>
<a class="sourceLine" id="cb321-62" data-line-number="62">lvls &lt;-<span class="st"> </span><span class="kw">unique</span>(<span class="kw">as.character</span>(y_test[[<span class="dv">1</span>]]))</a>
<a class="sourceLine" id="cb321-63" data-line-number="63">cols &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>,<span class="st">&quot;orange&quot;</span>,<span class="st">&quot;yellow&quot;</span>,<span class="st">&quot;green&quot;</span>,</a>
<a class="sourceLine" id="cb321-64" data-line-number="64">          <span class="st">&quot;blue&quot;</span>,<span class="st">&quot;purple&quot;</span>,<span class="st">&quot;violet&quot;</span>,<span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb321-65" data-line-number="65"></a>
<a class="sourceLine" id="cb321-66" data-line-number="66"><span class="co"># vapply helper function across levels</span></a>
<a class="sourceLine" id="cb321-67" data-line-number="67">auc &lt;-<span class="st"> </span><span class="kw">vapply</span>(lvls, roc_one_vs_all, <span class="kw">numeric</span>(<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb321-68" data-line-number="68"></a>
<a class="sourceLine" id="cb321-69" data-line-number="69"><span class="co"># tack on legend and non-informative line</span></a>
<a class="sourceLine" id="cb321-70" data-line-number="70"><span class="kw">legend</span>(<span class="st">&quot;bottomright&quot;</span>,</a>
<a class="sourceLine" id="cb321-71" data-line-number="71">       <span class="dt">legend=</span><span class="kw">paste</span>(<span class="st">&quot;PSI =&quot;</span>,lvls), </a>
<a class="sourceLine" id="cb321-72" data-line-number="72">       <span class="dt">col=</span>cols[<span class="kw">as.numeric</span>(lvls)], </a>
<a class="sourceLine" id="cb321-73" data-line-number="73">       <span class="dt">lty=</span><span class="dv">1</span>, </a>
<a class="sourceLine" id="cb321-74" data-line-number="74">       <span class="dt">cex=</span><span class="fl">1.0</span>)</a>
<a class="sourceLine" id="cb321-75" data-line-number="75"><span class="kw">lines</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),</a>
<a class="sourceLine" id="cb321-76" data-line-number="76">      <span class="dt">y=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),</a>
<a class="sourceLine" id="cb321-77" data-line-number="77">      <span class="dt">lty=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="04-Spatial_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb322-1" data-line-number="1"></a>
<a class="sourceLine" id="cb322-2" data-line-number="2"><span class="co"># display AUC metrics</span></a>
<a class="sourceLine" id="cb322-3" data-line-number="3"><span class="kw">print</span>(<span class="kw">tibble</span>(lvls, auc))</a>
<a class="sourceLine" id="cb322-4" data-line-number="4"><span class="co">## # A tibble: 4 x 2</span></a>
<a class="sourceLine" id="cb322-5" data-line-number="5"><span class="co">##   lvls    auc</span></a>
<a class="sourceLine" id="cb322-6" data-line-number="6"><span class="co">##   &lt;chr&gt; &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb322-7" data-line-number="7"><span class="co">## 1 4     0.650</span></a>
<a class="sourceLine" id="cb322-8" data-line-number="8"><span class="co">## 2 5     0.5  </span></a>
<a class="sourceLine" id="cb322-9" data-line-number="9"><span class="co">## 3 6     0.667</span></a>
<a class="sourceLine" id="cb322-10" data-line-number="10"><span class="co">## 4 7     0.818</span></a></code></pre></div>
<p>Assuming you’ve been following along with the daily activities, you can add this <code>Part 5</code> code to any of your algorithm scripts (e.g. <code>covid_19_rf.R</code>, <code>covid_19_knn.R</code>, <code>covid_19_svm.R</code>, etc.). The code uses the <code>inherits()</code> function to adapt the output of each individual algorithm into a form that is suitable for the ROC/AUC calculation.</p>
</div>
</div>
</div>
<div id="day-27" class="section level2">
<h2><span class="header-section-number">4.6</span> Day 27</h2>
<p>Today you’ll explore different combinations of features in your COVID-19 model.</p>
<ul>
<li><p>Select another 5 features and adjust <code>Part 2</code> and <code>Part 3</code> of your <code>covid_19_rf.R</code> script. In <code>Part 2</code> you’ll need to adjust the <code>my_x</code> variable and in <code>Part 3</code> you’ll need to adjust the model formula (e.g. <code>Y04 ~ X01 + ....</code>). Re-run the script and record the error rate, confusion matrix, and measures of parameter importance.</p></li>
<li><p>Repeat the above step after adding an additional 5 features.</p></li>
<li><p>How does the performance of the model change as more features are included?</p></li>
<li><p>Does any particular parameter stand out in terms of importance?</p></li>
<li><p>What does the most important parameter correspond to in termo of the metadata?</p></li>
</ul>
</div>
<div id="day-28" class="section level2">
<h2><span class="header-section-number">4.7</span> Day 28</h2>
<p>Today you’ll explore making some tweaks to the random forest model to see if you can improve its performance on the COVID-19 dataset. The algorithm parameters that you’ll be adjusting are described below:</p>
<ul>
<li><p><code>ntree</code> : The number of trees to grow. Default is 500.</p></li>
<li><p><code>mtry</code> : The number of variables randomly sampled as candidates at each split. Default is <code>sqrt(p)</code> where <code>p</code> is the number of features included in the model.</p></li>
</ul>
<p>Let’s perform some numerical experiments to explore how these algorithm parameters effect model performance:</p>
<ul>
<li><p>Setup a random forest model that has at least 16 features (see instructions from yesterday’s activity).</p></li>
<li><p>In <code>Part 3</code> of your <code>covid_19_rf.R</code> script, add the following arguments to the <code>randomForest()</code> function:</p>
<ul>
<li><p><code>ntree = 1000</code></p></li>
<li><p><code>mtry = 8</code></p></li>
</ul></li>
<li><p>Re-run the script and record the error rate, confusion matrix, and measures of parameter importance.</p></li>
<li><p>Repeat the above process using:</p>
<ul>
<li><p><code>ntree = 2000</code></p></li>
<li><p><code>mtry = 2</code></p></li>
</ul></li>
<li><p>Does adjusting the parameters effect the model performance? If so, what observations can you make?</p></li>
<li><p>Can you think of a “better” way to evaluate the influence of algorithm parameters?</p></li>
</ul>
<p>Congratulations - you made it through a week of machine learning boot camp! You can download completed scripts (i.e. <code>Part 1</code> through <code>Part 5</code>) for each algorithm using the links below:</p>
<ul>
<li><p><a href="assets/covid_19_rf.R">Complete Random Forest Example</a></p></li>
<li><p><a href="assets/covid_19_svm.R">Complete Support Vector Machine Example</a></p></li>
<li><p><a href="assets/covid_19_knn.R">Complete <span class="math inline">\(k\)</span>-Nearest Neighbors Example</a></p></li>
<li><p><a href="assets/covid_19_keras.R">Complete Keras Example</a></p></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="three.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="five.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["QuaRantine.pdf", "QuaRantine.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
