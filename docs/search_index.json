[
["three.html", "Week 3 Packages and the ‘tidyverse’ 3.1 Day 15 (Monday) Zoom check-in 3.2 Day 16 Key tidyverse packages: readr and dplyr 3.3 Day 17 Visualization with ggplot2 3.4 Day 18 Worldwide COVID data 3.5 Day 19 (Friday) Zoom check-in 3.6 Day 20 Exploring the course of pandemic in different regions 3.7 Day 21", " Week 3 Packages and the ‘tidyverse’ 3.1 Day 15 (Monday) Zoom check-in Review and troubleshoot (15 minutes) Over the weekend, I wrote two functions. The first retrieves and ‘cleans’ the US data set. get_US_data &lt;- function() { ## retrieve data from the internet url &lt;- &quot;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&quot; us &lt;- read.csv(url, stringsAsFactors = FALSE) ## update &#39;date&#39; from character vector to &#39;Date&#39;. this is the ## last line of executed code in the function, so the return ## value (the updated &#39;us&#39; object) is returned by the functino within(us, { date = as.Date(date, format = &quot;%Y-%m-%d&quot;) }) } The second plots data for a particular county and state plot_county &lt;- function(us_data, county_of_interest = &quot;Erie&quot;, state_of_interest = &quot;New York&quot;) { ## create the title for the plot main_title &lt;- paste( &quot;New Cases,&quot;, county_of_interest, &quot;County&quot;, state_of_interest ) ## subset the us data to just the county and state of interest county_data &lt;- subset( us_data, (county == county_of_interest) &amp; (state == state_of_interest) ) ## calculate new cases for particular county and state county_data &lt;- within(county_data, { new_cases &lt;- diff( c(0, cases) ) }) ## plot plot( new_cases ~ date, county_data, log = &quot;y&quot;, main = main_title) } I lived in Seattle (King County, Washington), for a while, and this is where the first serious outbreak occurred. Here’s the relevant data: us &lt;- get_US_data() plot_county(us, &quot;King&quot;, &quot;Washington&quot;) ## Warning in xy.coords(x, y, xlabel, ylabel, log): 1 y value &lt;= 0 omitted from ## logarithmic plot Packages (20 minutes) Base R R consists of ‘packages’ that implement different functionality. Each package contains functions that we can use, and perhaps data sets (like the mtcars) data set from Friday’s presentation) and other resources. R comes with several ‘base’ packages installed, and these are available in a new R session. Discover packages that are currently available using the search() function. This shows that the ‘stats’, ‘graphics’, ‘grDevices’, ‘utils’, ‘datasets’, ‘methods’, and ‘base’ packages, among others, are available in our current R session. &gt; search() ## [1] &quot;.GlobalEnv&quot; &quot;package:stats&quot; &quot;package:graphics&quot; ## [4] &quot;package:grDevices&quot; &quot;package:utils&quot; &quot;package:datasets&quot; ## [7] &quot;package:methods&quot; &quot;Autoloads&quot; &quot;package:base&quot; When we create a variable like x &lt;- c(1, 2, 3) R creates a new symbol in the .GlobalEnv location on the search path. When we evaluate a function like length(x)… R searches for the function length() along the search() path. It doesn’t find length() in the .GlobalEnv (because we didn’t define it there), or in the ‘stats’, ‘graphics’, … packages. Eventually, R finds the definition of length in the ‘base’ package. R then looks for the definition of x, finds it in the .GlobalEnv. Finally, R applies the definition of length found in the base package to the value of x found in the .GlobalEnv. Contributed packages R would be pretty limited if it could only do things that are defined in the base packages. It is ‘easy’ to write a package, and to make the package available for others to use. A major repository of contributed packages is CRAN – the Comprehensive R Archive Network. There are more than 15,000 packages in CRAN. Many CRAN packages are arranged in task views that highlight the most useful packages. Installing and attaching packages There are too many packages for all to be distributed with R, so it is necessary to install contributed packages that you might find interesting. once a package is installed (you only need to install a package once), it can be ‘loaded’ and ‘attached’ to the search path using library(). As an exercise, try to attach the ‘readr’, ‘dplyr’, and ‘ggplot2’ packages library(readr) library(dplyr) library(ggplot2) If any of these fails with a message like library(&quot;dplyr&quot;) ## Error in library(&quot;dplyr&quot;) : there is no package called &#39;dplyr&#39; it means that the package has not been installed (or that you have a typo in the name of the library!) Install any package that failed when library() was called with install.packages(c(&quot;readr&quot;, &quot;dplyr&quot;), repos = &quot;https://cran.r-project.org&quot;) Alternatively, use the RStudio interface to select (in the lower right panel, by default) the ‘Packages’ tab, ‘Install’ button. One package may use functions from one or more other packages, so when you install, for instance ‘dplyr’, you may actually install several packages. The ‘tidyverse’ of packages (20 minutes) The ‘tidyverse’ of packages provides a very powerful paradigm for working with data. Based on the idea that a first step in data analysis is to transform the data into a standard format. Subsequent steps can then be accomplished in a much more straight-forward way, using a small set of functions. Hadley Wickham’s ‘Tidy Data’ paper provides a kind of manifesto for what constitutes tidy data: Each variable forms a column. Each observation forms a row. Each type of observational unit forms a table We’ll look at the readr package for data input, and the dplyr package for essential data manipulation. readr for fast data input Load (install if necessary!) and attach the readr package library(readr) ## if it fails to load, try ## install.packages(&quot;readr&quot;, repos = &quot;https://cran.r-project.org&quot;) Example: US COVID data. N.B., readr::read_csv() rather than read.csv() url &lt;- &quot;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&quot; us &lt;- read_csv(url) ## Parsed with column specification: ## cols( ## date = col_date(format = &quot;&quot;), ## county = col_character(), ## state = col_character(), ## fips = col_character(), ## cases = col_double(), ## deaths = col_double() ## ) us ## # A tibble: 92,592 x 6 ## date county state fips cases deaths ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-01-21 Snohomish Washington 53061 1 0 ## 2 2020-01-22 Snohomish Washington 53061 1 0 ## 3 2020-01-23 Snohomish Washington 53061 1 0 ## 4 2020-01-24 Cook Illinois 17031 1 0 ## 5 2020-01-24 Snohomish Washington 53061 1 0 ## 6 2020-01-25 Orange California 06059 1 0 ## 7 2020-01-25 Cook Illinois 17031 1 0 ## 8 2020-01-25 Snohomish Washington 53061 1 0 ## 9 2020-01-26 Maricopa Arizona 04013 1 0 ## 10 2020-01-26 Los Angeles California 06037 1 0 ## # … with 92,582 more rows The us data is now represented as a tibble: a nicer data.frame Note that date has been deduced correctly read_csv() does not coerce inputs to factor (no need to use stringsAsFactors = FALSE) The tibble displays nicely (first ten lines, with an indication of total lines) dplyr for data manipulation Load and attach the dplyr package. library(dplyr) dplyr implements a small number of verbs for data transformation A small set of functions that allow very rich data transformation All have the same first argument – the tibble to be transformed All allow ‘non-standard’ evaluation – use the variable name without quotes &quot;. filter() rows that meet specific criteria filter(us, state == &quot;New York&quot;, county == &quot;Erie&quot;) ## # A tibble: 43 x 6 ## date county state fips cases deaths ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-03-15 Erie New York 36029 3 0 ## 2 2020-03-16 Erie New York 36029 6 0 ## 3 2020-03-17 Erie New York 36029 7 0 ## 4 2020-03-18 Erie New York 36029 7 0 ## 5 2020-03-19 Erie New York 36029 28 0 ## 6 2020-03-20 Erie New York 36029 31 0 ## 7 2020-03-21 Erie New York 36029 38 0 ## 8 2020-03-22 Erie New York 36029 54 0 ## 9 2020-03-23 Erie New York 36029 87 0 ## 10 2020-03-24 Erie New York 36029 107 0 ## # … with 33 more rows dplyr uses the ‘pipe’ %&gt;% as a way to chain data and functions together us %&gt;% filter(state == &quot;New York&quot;, county == &quot;Erie&quot;) ## # A tibble: 43 x 6 ## date county state fips cases deaths ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-03-15 Erie New York 36029 3 0 ## 2 2020-03-16 Erie New York 36029 6 0 ## 3 2020-03-17 Erie New York 36029 7 0 ## 4 2020-03-18 Erie New York 36029 7 0 ## 5 2020-03-19 Erie New York 36029 28 0 ## 6 2020-03-20 Erie New York 36029 31 0 ## 7 2020-03-21 Erie New York 36029 38 0 ## 8 2020-03-22 Erie New York 36029 54 0 ## 9 2020-03-23 Erie New York 36029 87 0 ## 10 2020-03-24 Erie New York 36029 107 0 ## # … with 33 more rows The pipe works by transforming whatever is on the left-hand side of the %&gt;% to the first argument of the function on the right-hand side. Like filter(), most dplyr functions take as their first argument a tibble, and return a tibble. So the functions can be chained together, as in the following example. select() specific columns us %&gt;% filter(state == &quot;New York&quot;, county == &quot;Erie&quot;) %&gt;% select(state, county, date, cases) ## # A tibble: 43 x 4 ## state county date cases ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 New York Erie 2020-03-15 3 ## 2 New York Erie 2020-03-16 6 ## 3 New York Erie 2020-03-17 7 ## 4 New York Erie 2020-03-18 7 ## 5 New York Erie 2020-03-19 28 ## 6 New York Erie 2020-03-20 31 ## 7 New York Erie 2020-03-21 38 ## 8 New York Erie 2020-03-22 54 ## 9 New York Erie 2020-03-23 87 ## 10 New York Erie 2020-03-24 107 ## # … with 33 more rows Other common verbs (see tomorrow’s quarantine) mutate() (add or update) columns summarize() one or more columns group_by() one or more variables when performing computations. ungroup() removes the grouping. arrange() rows based on values in particular column(s); desc() in descending order. count() the number of times values occur Other ‘tidyverse’ packages Packages adopting the ‘tidy’ approach to data representation and management are sometimes referred to as the tidyverse. ggplot2 implements high-quality data visualization in a way consistent with tidy data representations. The tidyr package implements functions that help to transform data to ‘tidy’ format; we’ll use pivot_longer() later in the week. 3.2 Day 16 Key tidyverse packages: readr and dplyr Start a script for today. In the script Load the libraries that we will use library(readr) library(dplyr) If R responds with (similarly for dplyr) Error in library(readr) : there is no package called &#39;readr&#39; then you’ll need to install (just once per R installation) the readr pacakge install.packages(&quot;readr&quot;, repos = &quot;https://cran.r-project.org&quot;) Work through the following commands, adding appropriate lines to your script Read US COVID data. N.B., readr::read_csv() rather than read.csv() url &lt;- &quot;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&quot; us &lt;- read_csv(url) ## Parsed with column specification: ## cols( ## date = col_date(format = &quot;&quot;), ## county = col_character(), ## state = col_character(), ## fips = col_character(), ## cases = col_double(), ## deaths = col_double() ## ) us ## # A tibble: 92,592 x 6 ## date county state fips cases deaths ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-01-21 Snohomish Washington 53061 1 0 ## 2 2020-01-22 Snohomish Washington 53061 1 0 ## 3 2020-01-23 Snohomish Washington 53061 1 0 ## 4 2020-01-24 Cook Illinois 17031 1 0 ## 5 2020-01-24 Snohomish Washington 53061 1 0 ## 6 2020-01-25 Orange California 06059 1 0 ## 7 2020-01-25 Cook Illinois 17031 1 0 ## 8 2020-01-25 Snohomish Washington 53061 1 0 ## 9 2020-01-26 Maricopa Arizona 04013 1 0 ## 10 2020-01-26 Los Angeles California 06037 1 0 ## # … with 92,582 more rows filter() rows that meet specific criteria us %&gt;% filter(state == &quot;New York&quot;, county == &quot;Erie&quot;) ## # A tibble: 43 x 6 ## date county state fips cases deaths ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-03-15 Erie New York 36029 3 0 ## 2 2020-03-16 Erie New York 36029 6 0 ## 3 2020-03-17 Erie New York 36029 7 0 ## 4 2020-03-18 Erie New York 36029 7 0 ## 5 2020-03-19 Erie New York 36029 28 0 ## 6 2020-03-20 Erie New York 36029 31 0 ## 7 2020-03-21 Erie New York 36029 38 0 ## 8 2020-03-22 Erie New York 36029 54 0 ## 9 2020-03-23 Erie New York 36029 87 0 ## 10 2020-03-24 Erie New York 36029 107 0 ## # … with 33 more rows select() specific columns us %&gt;% filter(state == &quot;New York&quot;, county == &quot;Erie&quot;) %&gt;% select(state, county, date, cases) ## # A tibble: 43 x 4 ## state county date cases ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 New York Erie 2020-03-15 3 ## 2 New York Erie 2020-03-16 6 ## 3 New York Erie 2020-03-17 7 ## 4 New York Erie 2020-03-18 7 ## 5 New York Erie 2020-03-19 28 ## 6 New York Erie 2020-03-20 31 ## 7 New York Erie 2020-03-21 38 ## 8 New York Erie 2020-03-22 54 ## 9 New York Erie 2020-03-23 87 ## 10 New York Erie 2020-03-24 107 ## # … with 33 more rows mutate() (add or update) columns erie &lt;- us %&gt;% filter(state == &quot;New York&quot;, county == &quot;Erie&quot;) erie %&gt;% mutate(new_cases = diff(c(0, cases))) ## # A tibble: 43 x 7 ## date county state fips cases deaths new_cases ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-03-15 Erie New York 36029 3 0 3 ## 2 2020-03-16 Erie New York 36029 6 0 3 ## 3 2020-03-17 Erie New York 36029 7 0 1 ## 4 2020-03-18 Erie New York 36029 7 0 0 ## 5 2020-03-19 Erie New York 36029 28 0 21 ## 6 2020-03-20 Erie New York 36029 31 0 3 ## 7 2020-03-21 Erie New York 36029 38 0 7 ## 8 2020-03-22 Erie New York 36029 54 0 16 ## 9 2020-03-23 Erie New York 36029 87 0 33 ## 10 2020-03-24 Erie New York 36029 107 0 20 ## # … with 33 more rows summarize() one or more columns erie %&gt;% mutate(new_cases = diff(c(0, cases))) %&gt;% summarize( duration = n(), total_cases = max(cases), max_new_cases_per_day = max(new_cases), mean_new_cases_per_day = mean(new_cases), median_new_cases_per_day = median(new_cases) ) ## # A tibble: 1 x 5 ## duration total_cases max_new_cases_per… mean_new_cases_per… median_new_cases_… ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 43 2954 217 68.7 63 group_by() one or more variables when performing computations us_county_cases &lt;- us %&gt;% group_by(county, state) %&gt;% summarize(total_cases = max(cases)) us_state_cases &lt;- us_county_cases %&gt;% group_by(state) %&gt;% summarize(total_cases = sum(total_cases)) arrange() based on a particular column; desc() in descending order. us_county_cases %&gt;% arrange(desc(total_cases)) ## # A tibble: 2,859 x 3 ## # Groups: county [1,676] ## county state total_cases ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 New York City New York 158268 ## 2 Nassau New York 34522 ## 3 Suffolk New York 32059 ## 4 Cook Illinois 30574 ## 5 Westchester New York 27664 ## 6 Los Angeles California 19528 ## 7 Wayne Michigan 15748 ## 8 Bergen New Jersey 14965 ## 9 Hudson New Jersey 13708 ## 10 Essex New Jersey 12863 ## # … with 2,849 more rows us_state_cases %&gt;% arrange(desc(total_cases)) ## # A tibble: 55 x 2 ## state total_cases ## &lt;chr&gt; &lt;dbl&gt; ## 1 New York 290167 ## 2 New Jersey 113223 ## 3 Massachusetts 55060 ## 4 Illinois 43916 ## 5 California 43696 ## 6 Pennsylvania 42717 ## 7 Michigan 37761 ## 8 Florida 31535 ## 9 Louisiana 26782 ## 10 Connecticut 25284 ## # … with 45 more rows count() the number of times values occur (duration of the pandemic?) us %&gt;% count(county, state) %&gt;% arrange(desc(n)) ## # A tibble: 2,859 x 3 ## county state n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Snohomish Washington 97 ## 2 Cook Illinois 94 ## 3 Orange California 93 ## 4 Los Angeles California 92 ## 5 Maricopa Arizona 92 ## 6 Santa Clara California 87 ## 7 Suffolk Massachusetts 86 ## 8 San Francisco California 85 ## 9 Dane Wisconsin 82 ## 10 San Diego California 77 ## # … with 2,849 more rows 3.3 Day 17 Visualization with ggplot2 Setup Load packages we’ll use today library(readr) library(dplyr) library(ggplot2) library(tidyr) Remember that packages need to be installed before loading; if you see… &gt; library(ggplot2) ## Error in library(ggplot2) : there is no package called &#39;ggplot2&#39; …then you’ll need to install the package and try again install.packages(&quot;ggplot2&quot;, repos = &quot;https://cran.r-project.org&quot;) library(ggplot2) Input data using readr::read_csv() url &lt;- &quot;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&quot; us &lt;- read_csv(url) ## Parsed with column specification: ## cols( ## date = col_date(format = &quot;&quot;), ## county = col_character(), ## state = col_character(), ## fips = col_character(), ## cases = col_double(), ## deaths = col_double() ## ) Create the Erie county subset, with columns new_cases and new_deaths erie &lt;- us %&gt;% filter(county == &quot;Erie&quot;, state == &quot;New York&quot;) %&gt;% mutate( new_cases = diff(c(0, cases)), new_deaths = diff(c(0, deaths)) ) ggplot2 essentials The ‘gg’ in ggplot2 ‘Grammar of Graphics’ – a formal, scholarly system for describing and creating graphics. See the usage guide, and the data visualization chapter of R for Data Science. The reference section of the usage guide provides a good entry point A first plot Specify the data to use. Do this by (a) providing the tibble containing the data (erie) and (b) communicating the ‘aesthetics’ of the overall graph by specifying the x and y data columns – ggplot(erie, aes(x = date, y = new_cases)) Add a geom_ describing the geometric object used to represent the data, e.g., use geom_point() to represent the data as points. ggplot(erie, aes(date, cases)) + geom_point() Note that the plot is assembled by adding elements using a simple +. Connect the points with geom_line(). ggplot(erie, aes(date, cases)) + geom_point() + geom_line() Plots can actually be captured in a variable, e.g., p p &lt;- ggplot(erie, aes(date, cases)) + geom_point() … and then updated and displayed p + xlab(&quot;Date (2020)&quot;) + ylab(&quot;Cummulative cases&quot;) + ggtitle(&quot;Cases, Erie County, New York&quot;) Arguments to each geom influece how the geometry is displayed, e.g., p + geom_line(color = &quot;blue&quot;) COVID-19 in Erie county New cases Create a base plot using new_cases) p &lt;- ggplot(erie, aes(date, new_cases)) + geom_point() Visualize on a linear and a log-transformed y-axis p # linear p + scale_y_log10() ## Warning in self$trans$transform(x): NaNs produced ## Warning: Transformation introduced infinite values in continuous y-axis ## Warning: Removed 1 rows containing missing values (geom_point). Add a smoothed line to the plot. By default the smoothed line is a local regression appropriate for exploratory data analysis. Note the confidence bands displayed in the plot, and how they convey a measure of certainty about the fit. p + scale_y_log10() + geom_smooth() ## Warning in self$trans$transform(x): NaNs produced ## Warning: Transformation introduced infinite values in continuous y-axis ## Warning in self$trans$transform(x): NaNs produced ## Warning: Transformation introduced infinite values in continuous y-axis ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## Warning: Removed 3 rows containing non-finite values (stat_smooth). ## Warning: Removed 1 rows containing missing values (geom_point). Reflect on the presentation of data, especially how log-transformation and a clarifies our impression of the local progress of the pandemic. The local regression used by geom_smooth() can be replaced by a linear regressin with geom_smooth(method = &quot;lm&quot;). Create this plot and reflect on the assumptions and suitability of a linear model for this data. New cases and mortality It’s easy to separately plot deaths by updating the aesthetic in ggplot() ggplot(erie, aes(date, deaths)) + scale_y_log10() + geom_point() ## Warning: Transformation introduced infinite values in continuous y-axis What about ploting cases and deaths? Move the aes() argument to the individual geometries. Use different colors for each geometry ggplot(erie) + scale_y_log10() + geom_point(aes(date, cases), shape = &quot;|&quot;, color = &quot;blue&quot;) + geom_line(aes(date, cases), color = &quot;blue&quot;) + geom_point(aes(date, deaths), shape = &quot;|&quot;) + geom_line(aes(date, deaths)) ## Warning: Transformation introduced infinite values in continuous y-axis ## Warning: Transformation introduced infinite values in continuous y-axis Deaths lag behind cases by a week or so. ‘Long’ data and an alternative approach to plotting multiple curves. Let’s simplify the data to just the columns of interest for this exercise simple &lt;- erie %&gt;% select(date, cases, deaths) simple ## # A tibble: 43 x 3 ## date cases deaths ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-03-15 3 0 ## 2 2020-03-16 6 0 ## 3 2020-03-17 7 0 ## 4 2020-03-18 7 0 ## 5 2020-03-19 28 0 ## 6 2020-03-20 31 0 ## 7 2020-03-21 38 0 ## 8 2020-03-22 54 0 ## 9 2020-03-23 87 0 ## 10 2020-03-24 107 0 ## # … with 33 more rows Use tidyr::pivot_longer() to transform the two columns ‘cases’ and ‘deaths’ into a column that indicates ‘name’ and ‘value’; ‘name’ is ‘cases’ when the corresponding ‘value’ came from the ‘cases’ column, and similarly for ‘deaths’. See the help page ?tidyr::pivot_longer and tomorrow’s exercises for more on pivot_longer(). longer &lt;- simple %&gt;% pivot_longer( c(&quot;cases&quot;, &quot;deaths&quot;), names_to = &quot;metric&quot;, values_to = &quot;count&quot; ) longer ## # A tibble: 86 x 3 ## date metric count ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2020-03-15 cases 3 ## 2 2020-03-15 deaths 0 ## 3 2020-03-16 cases 6 ## 4 2020-03-16 deaths 0 ## 5 2020-03-17 cases 7 ## 6 2020-03-17 deaths 0 ## 7 2020-03-18 cases 7 ## 8 2020-03-18 deaths 0 ## 9 2020-03-19 cases 28 ## 10 2020-03-19 deaths 0 ## # … with 76 more rows Plot date and value, coloring points byname` ggplot(longer, aes(date, count, color = metric)) + scale_y_log10() + geom_point() ## Warning: Transformation introduced infinite values in continuous y-axis COVID-19 in New York State We’ll explore ‘facet’ visualizations, which create a panel of related plots Setup From the US data, extract Erie and Westchester counties and New York City. Use coi (‘counties of interest’) as a variable to hold this data coi &lt;- us %&gt;% filter( county %in% c(&quot;Erie&quot;, &quot;Westchester&quot;, &quot;New York City&quot;), state == &quot;New York&quot; ) %&gt;% select(date, county, cases, deaths) coi ## # A tibble: 154 x 4 ## date county cases deaths ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-03-01 New York City 1 0 ## 2 2020-03-02 New York City 1 0 ## 3 2020-03-03 New York City 2 0 ## 4 2020-03-04 New York City 2 0 ## 5 2020-03-04 Westchester 9 0 ## 6 2020-03-05 New York City 4 0 ## 7 2020-03-05 Westchester 17 0 ## 8 2020-03-06 New York City 5 0 ## 9 2020-03-06 Westchester 33 0 ## 10 2020-03-07 New York City 12 0 ## # … with 144 more rows Pivot cases and deaths into long form coi_longer &lt;- coi %&gt;% pivot_longer( c(&quot;cases&quot;, &quot;deaths&quot;), names_to = &quot;metric&quot;, values_to = &quot;count&quot; ) coi_longer ## # A tibble: 308 x 4 ## date county metric count ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2020-03-01 New York City cases 1 ## 2 2020-03-01 New York City deaths 0 ## 3 2020-03-02 New York City cases 1 ## 4 2020-03-02 New York City deaths 0 ## 5 2020-03-03 New York City cases 2 ## 6 2020-03-03 New York City deaths 0 ## 7 2020-03-04 New York City cases 2 ## 8 2020-03-04 New York City deaths 0 ## 9 2020-03-04 Westchester cases 9 ## 10 2020-03-04 Westchester deaths 0 ## # … with 298 more rows Visualization We can plot cases and deaths of each county… p &lt;- ggplot(coi_longer, aes(date, count, color = metric)) + scale_y_log10() + geom_point() p ## Warning: Transformation introduced infinite values in continuous y-axis … but this is too confusing. Separate each county into a facet p + facet_grid(rows=vars(county)) ## Warning: Transformation introduced infinite values in continuous y-axis Note the common scales on the x and y axes. Plotting counties as ‘rows’ of the graph emphasize temporal comparisons – e.g., the earlier onset of the pandemic in Westchester and New York City compared to Erie, and perhaps longer lag between new cases and deaths in Westchester. Plotting countes as ‘columns’ emphasizes comparison between number of cases and deaths – there are many more cases in New York City than in Erie County. p + facet_grid(cols=vars(county)) ## Warning: Transformation introduced infinite values in continuous y-axis COVID-19 nationally Setup Summarize the total (maximum) number of cases in each county and state county_summary &lt;- us %&gt;% group_by(county, state) %&gt;% summarize( cases = max(cases), deaths = max(deaths) ) county_summary ## # A tibble: 2,859 x 4 ## # Groups: county [1,676] ## county state cases deaths ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Abbeville South Carolina 27 0 ## 2 Acadia Louisiana 130 7 ## 3 Accomack Virginia 187 3 ## 4 Ada Idaho 615 15 ## 5 Adair Iowa 1 0 ## 6 Adair Kentucky 83 9 ## 7 Adair Missouri 12 0 ## 8 Adair Oklahoma 55 3 ## 9 Adams Colorado 1348 58 ## 10 Adams Idaho 3 0 ## # … with 2,849 more rows Now summarize the number of cases per state state_summary &lt;- county_summary %&gt;% group_by(state) %&gt;% summarize( cases = sum(cases), deaths = sum(deaths) ) %&gt;% arrange(desc(cases)) state_summary ## # A tibble: 55 x 3 ## state cases deaths ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 New York 290167 18145 ## 2 New Jersey 113223 5960 ## 3 Massachusetts 55060 2899 ## 4 Illinois 43916 1946 ## 5 California 43696 1723 ## 6 Pennsylvania 42717 1892 ## 7 Michigan 37761 3318 ## 8 Florida 31535 1108 ## 9 Louisiana 26782 1676 ## 10 Connecticut 25284 1932 ## # … with 45 more rows Plot the relationship between cases and deaths as a scatter plot ggplot(state_summary, aes(cases, deaths)) + scale_x_log10() + scale_y_log10() + geom_point() Create a ‘long’ version of the state summary. The transformations include making ‘state’ a factor with the ‘levels’ ordered from most- to least-affected state. This is a ‘trick’ so that states are ordered, when displayed, from most to least affected. The transformations also choose only the 20 most-affected states using head(20). state_longer &lt;- state_summary %&gt;% mutate( ## this &#39;trick&#39; causes &#39;state&#39; to be ordered from most to ## least cases, rather than alphabetically state = factor(state, levels = state) ) %&gt;% head(20) %&gt;% # look at the 20 states with the most cases pivot_longer( c(&quot;cases&quot;, &quot;deaths&quot;), names_to = &quot;metric&quot;, values_to = &quot;count&quot; ) state_longer ## # A tibble: 40 x 3 ## state metric count ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 New York cases 290167 ## 2 New York deaths 18145 ## 3 New Jersey cases 113223 ## 4 New Jersey deaths 5960 ## 5 Massachusetts cases 55060 ## 6 Massachusetts deaths 2899 ## 7 Illinois cases 43916 ## 8 Illinois deaths 1946 ## 9 California cases 43696 ## 10 California deaths 1723 ## # … with 30 more rows Use a dot plot to provide an alternative representation that is more easy to associated statsistics with individual states ggplot(state_longer, aes(x = count, y = state, color = metric)) + scale_x_log10() + geom_point() 3.4 Day 18 Worldwide COVID data Setup Start a new script and load the packages we’ll use library(readr) library(dplyr) library(ggplot2) library(tidyr) # specialized functions for transforming tibbles These packages should have been installed during previous quarantines. Source CSSE at Johns Hopkins University, available on github hopkins = &quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&quot; csv &lt;- read_csv(hopkins) ## Parsed with column specification: ## cols( ## .default = col_double(), ## `Province/State` = col_character(), ## `Country/Region` = col_character() ## ) ## See spec(...) for full column specifications. ‘Tidy’ data The data has initial columns describing region, and then a column for each date of the pandemic. There are 264 rows, corresponding to the different regions covered by the database. We want instead to ‘pivot’ the data, so that each row represents cases in a particular region on a particular date, analogous to the way the US data we have been investigating earlier has been arranged. tidyr provides functions for manipulating a tibble into ‘tidy’ format. tidyr::pivot_longer() takes a ‘wide’ data frame like csv, and allows us to transform it to the ‘long’ format we are interested in. I discovered how to work with pivot_longer() using its help page ?tidyr::pivot_longer The first argument represents columns to pivot or, as a convenience when these are negative values, columns we do not want to pivot. We do not want to pivot columns 1 through 4, so this argument will be -(1:4). The names_to argument is the column name we want to use to refer to the names of the columns that we do pivot. We’ll pivot the columns that have a date in them, so it makes sense to use names_to = &quot;date&quot;. The values_to argument is the column name we want to use for the pivoted values. Since the values in the main part of csv are the number of cases observed, we’ll use values_to = &quot;cases&quot; Here’s what we have after pivoting csv %&gt;% pivot_longer(-(1:4), names_to = &quot;date&quot;, values_to = &quot;cases&quot;) ## # A tibble: 25,608 x 6 ## `Province/State` `Country/Region` Lat Long date cases ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 &lt;NA&gt; Afghanistan 33 65 1/22/20 0 ## 2 &lt;NA&gt; Afghanistan 33 65 1/23/20 0 ## 3 &lt;NA&gt; Afghanistan 33 65 1/24/20 0 ## 4 &lt;NA&gt; Afghanistan 33 65 1/25/20 0 ## 5 &lt;NA&gt; Afghanistan 33 65 1/26/20 0 ## 6 &lt;NA&gt; Afghanistan 33 65 1/27/20 0 ## 7 &lt;NA&gt; Afghanistan 33 65 1/28/20 0 ## 8 &lt;NA&gt; Afghanistan 33 65 1/29/20 0 ## 9 &lt;NA&gt; Afghanistan 33 65 1/30/20 0 ## 10 &lt;NA&gt; Afghanistan 33 65 1/31/20 0 ## # … with 25,598 more rows We’d like to further clean this up data Format our newly created ‘date’ column (using as.Date(), but with a format= argument appropriate for the format of the dates in this data set) Re-name, for convenience, the County/Region column as just country. Select only columns of interest – country, date, cases Some countries have multiple rows, because the data is a provincial or state levels, so we would like to sum all cases, grouped by country and date world &lt;- csv %&gt;% pivot_longer(-(1:4), names_to = &quot;date&quot;, values_to = &quot;cases&quot;) %&gt;% mutate( country = `Country/Region`, date = as.Date(date, format = &quot;%m/%d/%y&quot;) ) %&gt;% group_by(country, date) %&gt;% summarize(cases = sum(cases)) world ## # A tibble: 17,945 x 3 ## # Groups: country [185] ## country date cases ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-01-22 0 ## 2 Afghanistan 2020-01-23 0 ## 3 Afghanistan 2020-01-24 0 ## 4 Afghanistan 2020-01-25 0 ## 5 Afghanistan 2020-01-26 0 ## 6 Afghanistan 2020-01-27 0 ## 7 Afghanistan 2020-01-28 0 ## 8 Afghanistan 2020-01-29 0 ## 9 Afghanistan 2020-01-30 0 ## 10 Afghanistan 2020-01-31 0 ## # … with 17,935 more rows Let’s also calculate new_cases by country Use group_by() to perform the new_cases computation for each country Use mutate() to calculate the new variable Use ungroup() to remove the grouping variable, so it doesn’t unexpectedly influence other calculations re-assign the updated tibble to the variable world world &lt;- world %&gt;% group_by(country) %&gt;% mutate(new_cases = diff(c(0, cases))) %&gt;% ungroup() Exploration Use group_by() and summarize() to find the maximum (total) number of cases, and arrange() these indesc()`ending order world %&gt;% group_by(country) %&gt;% summarize(n = max(cases)) %&gt;% arrange(desc(n)) ## # A tibble: 185 x 2 ## country n ## &lt;chr&gt; &lt;dbl&gt; ## 1 US 988197 ## 2 Spain 229422 ## 3 Italy 199414 ## 4 France 165963 ## 5 Germany 158758 ## 6 United Kingdom 158348 ## 7 Turkey 112261 ## 8 Iran 91472 ## 9 Russia 87147 ## 10 China 83918 ## # … with 175 more rows Visualization Start by creating a subset, e.g., the US country &lt;- &quot;US&quot; us &lt;- world %&gt;% filter(country == &quot;US&quot;) Use ggplot2 to visualize the progression of the pandemic ggplot(us, aes(date, new_cases)) + scale_y_log10() + geom_point() + geom_smooth() + ggtitle(paste(&quot;Country:&quot;, country)) ## Warning: Transformation introduced infinite values in continuous y-axis ## Warning: Transformation introduced infinite values in continuous y-axis ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## Warning: Removed 25 rows containing non-finite values (stat_smooth). It seems like it would be convenient to capture our data cleaning and visualization steps into separate functions that can be re-used, e.g., on different days or for different visualizations. write a function for data retrieval and cleaning get_world_data &lt;- function() { ## read data from Hopkins&#39; github repository hopkins = &quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&quot; csv &lt;- read_csv(hopkins) ## &#39;tidy&#39; the data world &lt;- csv %&gt;% pivot_longer(-(1:4), names_to = &quot;date&quot;, values_to = &quot;cases&quot;) %&gt;% mutate( country = `Country/Region`, date = as.Date(date, format = &quot;%m/%d/%y&quot;) ) ## sum cases across regions within aa country world &lt;- world %&gt;% group_by(country, date) %&gt;% summarize(cases = sum(cases)) ## add `new_cases`, and return the result world %&gt;% group_by(country) %&gt;% mutate(new_cases = diff(c(0, cases))) %&gt;% ungroup() } …and for plotting by country plot_country &lt;- function(tbl, view_country = &quot;US&quot;) { country_title &lt;- paste(&quot;Country:&quot;, view_country) ## subset to just this country country_data &lt;- tbl %&gt;% filter(country == view_country) ## plot country_data %&gt;% ggplot(aes(date, 1 + new_cases)) + scale_y_log10() + geom_point() + ## add method and formula to quieten message geom_smooth(method = &quot;loess&quot;, formula = y ~ x) + ggtitle(country_title) } Note that, because the first argument of plot_country() is a tibble, the output of get_world_data() can be used as the input of plot_country(), and can be piped together, e.g., world &lt;- get_world_data() ## Parsed with column specification: ## cols( ## .default = col_double(), ## `Province/State` = col_character(), ## `Country/Region` = col_character() ## ) ## See spec(...) for full column specifications. world %&gt;% plot_country(&quot;Korea, South&quot;) 3.5 Day 19 (Friday) Zoom check-in 3.5.1 Review and trouble shoot (25 minutes) 3.5.2 Next week (25 minutes) 3.6 Day 20 Exploring the course of pandemic in different regions Use the data and functions from quarantine day 18 to place the pandemic into quantitative perspective. Start by retrieving the current data world &lt;- get_world_data() Start with the United States world %&gt;% plot_country(&quot;US&quot;) When did ‘stay at home’ orders come into effect? Did they appear to be effective? When would the data suggest that the pandemic might be considered ‘under control’, and country-wide stay-at-home orders might be relaxed? Explore other countries. The longest trajectory is probably displayed by China world %&gt;% plot_country(&quot;China&quot;) Italy and Spain were hit very hard, and relatively early, by the pandemic world %&gt;% plot_country(&quot;Italy&quot;) world %&gt;% plot_country(&quot;Spain&quot;) Austria relaxed quarantine very early, in the middle of April; does that seem like a good idea? world %&gt;% plot_country(&quot;Austria&quot;) Germany also had strong leadership (e.g., chancellor Angela Merkel provided clear and unambiguous rules for Germans to follow, and then self-isolated when her doctor, whom she had recently visited, tested positive) and an effective screening campaign (e.g., to make effective use of limited testing resources, in some instances pools of samples were screened, and only if the pool indicated infection were the individuals in the pool screened. world %&gt;% plot_country(&quot;Germany&quot;) At the start of the pandemic, Singapore had excellent surveillance (detecting individuals with symptoms) and contact tracing (identifying and placing in quarantine those individuals coming in contact with the infected individuals). New cases were initially very low, despite proximity to China, and Singapore managed the pandemic through only moderate social distancing (e.g., workers were encouraged to operate in shifts; stores and restaurants remained open). Unfortunately, Singaporeans returning from Europe (after travel restrictions were in place there) introduced new cases that appear to have overwhelmed the surveillance network. Later, the virus spread to large, densely populated migrant work housing. Singapore’s initial success at containing the virus seems to have fallen apart in the face of this wider spread, and more severe restrictions on economic and social life were imposed. world %&gt;% plot_country(&quot;Singapore&quot;) South Korea had a very ‘acute’ spike in cases associated with a large church. The response was to deploy very extensive testing and use modern approaches to tracking (e.g., cell phone apps) coupled with transparent accounting. South Korea imposed relatively modest social and economic restrictions. It seems like this has effectively ‘flattened the curve’ without pausing the economy. world %&gt;% plot_country(&quot;Korea, South&quot;) Where does your own exploration of the data take you? 3.7 Day 21 Self-directed activities. "]
]
